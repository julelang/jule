// Copyright 2023-2025 The Jule Programming Language.
// Use of this source code is governed by a BSD 3-Clause
// license that can be found in the LICENSE file.

// The Jule code is a modified version of the original Go code from
// https://github.com/golang/go/blob/go1.20/src/encoding/csv/reader.go and came with this notice.
//
// ====================================================
// Copyright (c) 2009 The Go Authors. All rights reserved.
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are
// met:
//
//    * Redistributions of source code must retain the above copyright
// notice, this list of conditions and the following disclaimer.
//    * Redistributions in binary form must reproduce the above
// copyright notice, this list of conditions and the following disclaimer
// in the documentation and/or other materials provided with the
// distribution.
//    * Neither the name of Google Inc. nor the names of its
// contributors may be used to endorse or promote products derived from
// this software without specific prior written permission.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
// "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
// ====================================================

// Package csv reads and writes comma-separated values (CSV) files.
// There are many kinds of CSV files; this package supports the format
// described in RFC 4180.
//
// A csv file contains zero or more records of one or more fields per record.
// Each record is separated by the newline character. The final record may
// optionally be followed by a newline character.
//
//	field1,field2,field3
//
// White space is considered part of a field.
//
// Carriage returns before newline characters are silently removed.
//
// Blank lines are ignored. A line with only whitespace characters (excluding
// the ending newline character) is not considered a blank line.
//
// Fields which start and stop with the quote character " are called
// quoted-fields. The beginning and ending quote are not part of the
// field.
//
// The source:
//
//	normal string,"quoted-field"
//
// results in the fields
//
//	{`normal string`, `quoted-field`}
//
// Within a quoted-field a quote character followed by a second quote
// character is considered a single quote.
//
//	"the ""word"" is true","a ""quoted-field"""
//
// results in
//
//	{`the "word" is true`, `a "quoted-field"`}
//
// Newlines and commas may be included in a quoted-field
//
//	"Multi-line
//	field","comma is ,"
//
// results in
//
//	{`Multi-line
//	field`, `comma is ,`}

use "std/bytes"
use "std/errors"
use "std/fmt"
use "std/io"
use "std/unicode"
use "std/unicode/utf8"

// A ParseError is returned for parsing errors.
// Line and column numbers are 1-indexed.
struct ParseError {
	StartLine: int // Line where the record starts
	Line:      int // Line where the error occurred
	Column:    int // Column (1-based byte index) where the error occurred
	Err:       any // The actual error
}

impl ParseError {
	fn Str(*self): str {
		if self.Err == ErrFieldCount {
			ret fmt::Sprintf("record on line {}: {}", self.Line, self.Err)
		}
		if self.StartLine != self.Line {
			ret fmt::Sprintf("record on line {}; parse error on line {}, column {}: {}", self.StartLine, self.Line, self.Column, self.Err)
		}
		ret fmt::Sprintf("parse error on line {}, column {}: {}", self.Line, self.Column, self.Err)
	}
}

// These are the errors that can be returned in [ParseError.Err].
// Mutation is undefined behavior.
let mut ErrBareQuote = errors::New("bare \" in non-quoted-field")
let mut ErrQuote = errors::New("extraneous or missing \" in quoted-field")
let mut ErrFieldCount = errors::New("wrong number of fields")

let mut errInvalidDelim = errors::New("csv: invalid field or comment delimiter")

// Holds the position of a field in the current line.
struct position {
	line: int
	col:  int
}

// A Reader reads records from a CSV-encoded file.
//
// As returned by [new], a Reader expects input conforming to RFC 4180.
// The exported fields can be changed to customize the details before the
// first call to [Reader.Read] or [Reader.ReadAll].
//
// The Reader converts all \r\n sequences in its input to plain \n,
// including in multiline field values, so that the returned data does
// not depend on which line-ending convention an input file uses.
struct Reader {
	// The field delimiter.
	// It is set to comma (',') by NewReader.
	// Comma must be a valid rune and must not be \r, \n,
	// or the Unicode replacement character (0xFFFD).
	Comma: rune

	// Comment, if not 0, is the comment character. Lines beginning with the
	// Comment character without preceding whitespace are ignored.
	// With leading whitespace the Comment character becomes part of the
	// field, even if TrimLeadingSpace is true.
	// Comment must be a valid rune and must not be \r, \n,
	// or the Unicode replacement character (0xFFFD).
	// It must also not be equal to comma.
	Comment: rune

	// The number of expected fields per record.
	// If FieldsPerRecord is positive, read requires each record to
	// have the given number of fields. If FieldsPerRecord is 0, read sets it to
	// the number of fields in the first record, so that future records must
	// have the same field count. If FieldsPerRecord is negative, no check is
	// made and records may have a variable number of fields.
	FieldsPerRecord: int

	// If it is true, a quote may appear in an unquoted field and a
	// non-doubled quote may appear in a quoted field.
	LazyQuotes: bool

	// If it is true, leading white space in a field is ignored.
	// This is done even if the field delimiter, comma, is white space.
	TrimLeadingSpace: bool

	// Controls whether calls to read may return a slice sharing
	// the backing array of the previous call's returned slice for performance.
	// By default, each call to read returns newly allocated memory owned by the caller.
	ReuseRecord: bool

	r: &bufreader

	// The current line being read in the CSV file.
	numLine: int

	// The input stream byte offset of the current reader position.
	offset: i64

	// Holds the unescaped fields, one after another.
	// The fields can be accessed by using the indexes in fieldIndexes.
	// E.g., For the row `a,"b","c""d",e`, recordBuffer will contain `abc"de`
	// and fieldIndexes will contain the indexes [1, 2, 5, 6].
	recordBuffer: []byte

	// Index of fields inside recordBuffer.
	// The i'th field ends at offset fieldIndexes[i] in recordBuffer.
	fieldIndexes: []int

	// fieldPositions is an index of field positions for the
	// last record returned by Read.
	fieldPositions: []position

	// Record cache and only used when ReuseRecord == true.
	lastRecord: []str
}

impl Reader {
	// Returns new Reader instance that reads r.
	fn New(mut r: io::Reader): &Reader {
		ret &Reader{
			Comma: ',',
			r: bufreader.new(r),
		}
	}

	// Returns the input stream byte offset of the current reader
	// position. The offset gives the location of the end of the most recently
	// read row and the beginning of the next row.
	fn InputOffset(*self): i64 {
		ret self.offset
	}

	// Reads one record (a slice of fields) from r.
	// If the record has an unexpected number of fields,
	// read returns the [ErrFieldCount] as exception.
	// If there is no data left to be read, read returns nil.
	// If [self.ReuseRecord] is true, the returned slice may be shared
	// between multiple calls to read.
	fn Read(mut *self)!: (record: []str) {
		if self.ReuseRecord {
			record = self.readRecord(self.lastRecord) else { error(error) }
			self.lastRecord = record
		} else {
			record = self.readRecord(nil) else { error(error) }
		}
		ret
	}

	// Returns the line and column corresponding to
	// the start of the field with the given index in the slice most recently
	// returned by [read]. Numbering of lines and columns starts at 1;
	// columns are counted in bytes, not runes.
	//
	// If this is called with an out-of-bounds index, it panics.
	fn FieldPos(*self, field: int): (line: int, column: int) {
		if field < 0 || field >= len(self.fieldPositions) {
			panic("csv: Reader: out of range index passed to fieldPos")
		}
		p := &self.fieldPositions[field]
		unsafe {
			ret p.line, p.col
		}
	}

	// Reads all the remaining records from r.
	// Each record is a slice of fields.
	fn ReadAll(mut *self)!: (records: [][]str) {
		for {
			mut record := self.readRecord(nil) else { error(error) }
			if len(record) == 0 {
				break
			}
			records = append(records, record)
		}
		ret
	}

	// Reads the next line (with the trailing endline).
	// If EOF is hit without a trailing endline, it will be omitted.
	// The result is only valid until the next call to readLine.
	fn readLine(mut *self)!: []byte {
		mut line := self.r.readSlice('\n') else { error(error) }
		mut readSize := len(line)
		if readSize > 0 {
			// For backwards compatibility, drop trailing \r before EOF.
			if line[readSize-1] == '\r' {
				line = line[:readSize-1]
			}
		}
		self.numLine++
		self.offset += i64(readSize)
		// Normalize \r\n to \n on all input lines.
		n := len(line)
		if n >= 2 && line[n-2] == '\r' && line[n-1] == '\n' {
			line[n-2] = '\n'
			line = line[:n-1]
		}
		ret line
	}

	fn readRecord(mut *self, mut dst: []str)!: []str {
		if self.Comma == self.Comment ||
			!validDelim(self.Comma) ||
			(self.Comment != 0 && !validDelim(self.Comment)) {
			error(errInvalidDelim)
		}

		// Read line (automatically skipping past empty lines and any comments).
		let mut line: []byte
		for {
			line = self.readLine() else { error(error) }
			if len(line) == 0 {
				ret nil
			}
			if self.Comment != 0 && nextRune(line) == self.Comment {
				line = nil
				continue // Skip comment lines
			}
			if len(line) == lengthNl(line) {
				line = nil
				continue // Skip empty lines
			}
			break
		}

		// Parse each field in the record.
		const QuoteLen = len(`"`)
		commaLen := utf8::RuneLen(self.Comma)
		mut recLine := self.numLine // Starting line for record
		self.recordBuffer = self.recordBuffer[:0]
		self.fieldIndexes = self.fieldIndexes[:0]
		self.fieldPositions = self.fieldPositions[:0]
		mut pos := position{line: self.numLine, col: 1}
	parseField:
		for {
			if self.TrimLeadingSpace {
				mut i := bytes::IndexFunc(line, fn|r| !unicode::IsSpace(r))
				if i == -1 {
					i = len(line)
					pos.col -= lengthNl(line)
				}
				line = line[i:]
				pos.col += i
			}
			if len(line) == 0 || line[0] != '"' {
				// Non-quoted string field
				i := bytes::IndexRune(line, self.Comma)
				mut field := line
				if i >= 0 {
					field = field[:i]
				} else {
					field = field[:len(field)-lengthNl(field)]
				}
				// Check to make sure a quote does not appear in field.
				if !self.LazyQuotes {
					j := bytes::IndexByte(field, '"')
					if j >= 0 {
						error(&ParseError{
							StartLine: recLine,
							Line: self.numLine,
							Column: pos.col + j,
							Err: ErrBareQuote,
						})
						break parseField
					}
				}
				self.recordBuffer = append(self.recordBuffer, field...)
				self.fieldIndexes = append(self.fieldIndexes, len(self.recordBuffer))
				self.fieldPositions = append(self.fieldPositions, pos)
				if i >= 0 {
					line = line[i+commaLen:]
					pos.col += i + commaLen
					continue parseField
				}
				break parseField
			} else {
				// Quoted string field
				fieldPos := pos
				line = line[QuoteLen:]
				pos.col += QuoteLen
				for {
					i := bytes::IndexByte(line, '"')
					if i >= 0 {
						// Hit next quote.
						self.recordBuffer = append(self.recordBuffer, line[:i]...)
						line = line[i+QuoteLen:]
						pos.col += i + QuoteLen
						rn := nextRune(line)
						match {
						| rn == '"':
							// `""` sequence (append quote).
							self.recordBuffer = append(self.recordBuffer, '"')
							line = line[QuoteLen:]
							pos.col += QuoteLen
						| rn == self.Comma:
							// `",` sequence (end of field).
							line = line[commaLen:]
							pos.col += commaLen
							self.fieldIndexes = append(self.fieldIndexes, len(self.recordBuffer))
							self.fieldPositions = append(self.fieldPositions, fieldPos)
							continue parseField
						| lengthNl(line) == len(line):
							// `"\n` sequence (end of line).
							self.fieldIndexes = append(self.fieldIndexes, len(self.recordBuffer))
							self.fieldPositions = append(self.fieldPositions, fieldPos)
							break parseField
						| self.LazyQuotes:
							// `"` sequence (bare quote).
							self.recordBuffer = append(self.recordBuffer, '"')
						|:
							// `"*` sequence (invalid non-escaped quote).
							error(&ParseError{
								StartLine: recLine,
								Line: self.numLine,
								Column: pos.col - QuoteLen,
								Err: ErrQuote,
							})
							break parseField
						}
					} else if len(line) > 0 {
						// Hit end of line (copy all data so far).
						self.recordBuffer = append(self.recordBuffer, line...)
						pos.col += len(line)
						line = self.readLine() else { error(error) }
						if len(line) > 0 {
							pos.line++
							pos.col = 1
						}
					} else {
						// Abrupt end of file (EOF or error).
						if !self.LazyQuotes {
							error(&ParseError{
								StartLine: recLine,
								Line: pos.line,
								Column: pos.col,
								Err: ErrQuote,
							})
							break parseField
						}
						self.fieldIndexes = append(self.fieldIndexes, len(self.recordBuffer))
						self.fieldPositions = append(self.fieldPositions, fieldPos)
						break parseField
					}
				}
			}
		}

		// Create a single string and create slices out of it.
		// This pins the memory of the fields together, but allocates once.
		s := str(self.recordBuffer) // Convert to string once to batch allocations
		dst = dst[:0]
		if cap(dst) < len(self.fieldIndexes) {
			dst = make([]str, len(self.fieldIndexes))
		}
		dst = dst[:len(self.fieldIndexes)]
		mut preIdx := 0
		for i, idx in self.fieldIndexes {
			dst[i] = s[preIdx:idx]
			preIdx = idx
		}

		// Check or update the expected fields per record.
		if self.FieldsPerRecord > 0 {
			if len(dst) != self.FieldsPerRecord {
				error(&ParseError{
					StartLine: recLine,
					Line: recLine,
					Column: 1,
					Err: ErrFieldCount,
				})
			}
		} else if self.FieldsPerRecord == 0 {
			self.FieldsPerRecord = len(dst)
		}
		ret dst
	}
}

fn validDelim(r: rune): bool {
	ret r != 0 &&
		r != '"' &&
		r != '\r' &&
		r != '\n' &&
		utf8::ValidRune(r) &&
		r != utf8::RuneError
}

// Returns the next rune in b or utf8::RuneError.
fn nextRune(b: []byte): rune {
	r, _ := utf8::DecodeRune(b)
	ret r
}

// Reports the number of bytes for the trailing \n.
fn lengthNl(b: []byte): int {
	if len(b) > 0 && b[len(b)-1] == '\n' {
		ret 1
	}
	ret 0
}

struct bufreader {
	buf: []byte
	rd:  io::Reader // reader provided by the client
	r:   int
	w:   int
}

impl bufreader {
	fn new(mut r: io::Reader): &bufreader {
		const defaultBufSize = 4096
		mut br := new(bufreader)
		br.buf = make([]byte, defaultBufSize)
		br.rd = r
		ret br
	}

	fn readSlice(mut *self, delim: byte)!: (line: []byte) {
		mut n := 0
		for {
			i := bytes::IndexByte(self.buf[self.r:], delim)
			if i >= 0 {
				line = self.buf[self.r : self.r+i+1]
				self.r += i + 1
				ret
			}
			if self.r >= len(self.buf) {
				mut buf := make([]byte, len(self.buf)*2)
				copy(buf, self.buf)
				self.buf = buf
			}
			w := self.rd.Read(self.buf[self.r+n:]) else { error(error) }
			if w == 0 {
				line = self.buf[self.r:self.w]
				self.r = self.w
				ret
			}
			n += w
			self.w += w
		}
	}
}