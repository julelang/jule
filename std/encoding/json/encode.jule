// Copyright 2024-2025 The Jule Programming Language.
// Use of this source code is governed by a BSD 3-Clause
// license that can be found in the LICENSE file.

use "std/comptime"
use "std/conv"
use "std/encoding/base64"
use "std/internal/ubuf"
use "std/math"
use "std/runtime"
use "std/strings"
use "std/sync"
use "std/unicode"
use "std/unicode/utf8"
use "std/unsafe"

// Returned by [Encode] and [EncodeIndent] when attempting
// to encode an unsupported value type.
struct UnsupportedTypeError {
	Type: str
}

impl UnsupportedTypeError {
	fn Str(self): str {
		ret "json: unsupported type: " + self.Type
	}
}

// Returned by [Encode] and [EncodeIndent] when attempting
// to encode an unsupported value.
struct UnsupportedValueError {
	Value: str
}

impl UnsupportedValueError {
	fn Str(self): str {
		ret "json: unsupported value: " + self.Value
	}
}

// Represents an error from calling a reserved [EncodeText] method.
struct EncodeError {
	Type:       str
	Err:        any
	sourceFunc: str
}

impl EncodeError {
	fn Str(self): str {
		ret "json: error calling " +
			self.sourceFunc + " for type " +
			self.Type + ": " + runtime::toStr(self.Err)
	}
}

const hex = "0123456789abcdef"

// JSON encoder implementation flags, by types.
// This JSON encoding algorithm is based comptime and uses generics.
// Since we do not want implement overhead of indentation handling for plain
// encoding calls, we have to make separate implementations for plain and
// indentation-based encoding algorithms. But this approach is hard to maintain.
// Therefore we use opportunity of the generic types and Jule's comptime power.
// All generic encoding algorithms use also Flag generic type to instantiate same
// implementation separately for plain and indentation-based encoding algorithms,
// and use Jule's comptime power to determine Flag whether enables indentation
// algorithms. Thus, we can have separated algorithms for plain and
// indentation-based encoding algorithms.

// Flag type for plain JSON encoding without indentation.
// When this type used for Flag type, indentation algorithms will be excluded.
type encodePlain = int

// Flag type for JSON encoding with indentation.
// When this type used for Flag type, indentation algorithms will be included.
// Encoder will add indentation when needed.
type encodeIndent = uint

// JSON encoder with/without indentation.
// For indentation, use Flag type logic.
// See documentation of the [encodeFlagType].
// See documentation of the Encode[T] for encoding details.
struct jsonEncoder {
	buf:        buffer // Common internal buffer to encode JSON.
	indent:     str    // Indentation.
	depth:      int    // Current depth.
	escapeHTML: bool
}

impl jsonEncoder {
	fn encodeNil(mut self) {
		self.buf.writeStr("null")
	}

	fn encodeBool(mut self, b: bool) {
		if b {
			self.buf.writeStr("true")
		} else {
			self.buf.writeStr("false")
		}
	}

	fn encodeInt(mut self, x: i64) {
		mut b := self.buf.availableBuffer()
		b = conv::AppendInt(b, x, 10)
		self.buf.write(b)
	}

	fn encodeUint(mut self, x: u64) {
		mut b := self.buf.availableBuffer()
		b = conv::AppendUint(b, x, 10)
		self.buf.write(b)
	}

	fn encodeFloat(mut self, f: f64, bits: int)! {
		if math::IsNaN(f) || math::IsInf(f, 0) {
			error(&UnsupportedValueError{conv::FormatFloat(f, 'g', -1, bits)})
		}
		mut fmt := byte('f')
		abs := math::Abs(f)
		// Note: Must use f32 comparisons for underlying f32 value to get precise cutoffs right.
		if abs != 0 {
			if bits == 64 && (abs < 1e-6 || abs >= 1e21) ||
				bits == 32 && (f32(abs) < 1e-6 || f32(abs) >= 1e21) {
				fmt = 'e'
			}
		}
		bb := ubuf::Ubuf{}
		bb.SetData(conv::AppendFloat(self.buf.availableBuffer(), f, fmt, -1, bits))
		if fmt == 'e' {
			// clean up e-09 to e-9
			n := bb.Len()
			if n >= 4 && bb.Get(n-4) == 'e' && bb.Get(n-3) == '-' && bb.Get(n-2) == '0' {
				bb.Set(n-2, bb.Get(n-1))
				bb.SetLen(n - 1)
			}
		}
		self.buf.write(bb.Slice1(0))
	}

	fn encodeStr(mut self, s: str) {
		ss := ubuf::Ubuf{}
		ss.SetData(unsafe::StrBytes(s))
		self.buf.writeByte('"')
		mut start := 0
		mut i := 0
		for i < ss.Len() {
			b := ss.Get(i)
			if b < utf8::RuneSelf {
				if isHTMLSafe(b) || (!self.escapeHTML && isSafe(b)) {
					i++
					continue
				}
				self.buf.write(ss.Slice2(start, i))
				match b {
				| '\\':
					self.buf.writeStr(`\\`)
				| '"':
					self.buf.writeStr(`\"`)
				| '\b':
					self.buf.writeStr(`\b`)
				| '\f':
					self.buf.writeStr(`\f`)
				| '\n':
					self.buf.writeStr(`\n`)
				| '\r':
					self.buf.writeStr(`\r`)
				| '\t':
					self.buf.writeStr(`\t`)
				|:
					// This encodes bytes < 0x20 except for \b, \f, \n, \r and \t.
					// If escapeHTML is set, it also escapes <, >, and &
					// because they can lead to security holes when
					// user-controlled strings are rendered into JSON
					// and served to some browsers.
					self.buf.writeStr(`\u00`)
					self.buf.writeByte(hex[b>>4])
					self.buf.writeByte(hex[b&0xF])
				}
				i++
				start = i
				continue
			}
			mut n := ss.Len() - i
			if n > utf8::UTFMax {
				n = utf8::UTFMax
			}
			c, size := utf8::DecodeRune(ss.Slice2(i, i+n))
			if c == utf8::RuneError && size == 1 {
				self.buf.write(ss.Slice2(start, i))
				self.buf.writeStr(`\ufffd`)
				i += size
				start = i
				continue
			}
			// U+2028 is LINE SEPARATOR.
			// U+2029 is PARAGRAPH SEPARATOR.
			// They are both technically valid characters in JSON strings,
			// but don't work in JSONP, which has to be evaluated as JavaScript,
			// and can lead to security holes there. It is valid JSON to
			// escape them, so we do so unconditionally.
			// See https://en.wikipedia.org/wiki/JSON#Safety.
			if c == '\u2028' || c == '\u2029' {
				self.buf.write(ss.Slice2(start, i))
				self.buf.writeStr(`\u202`)
				self.buf.writeByte(hex[c&0xF])
				i += size
				start = i
				continue
			}
			i += size
		}
		self.buf.write(ss.Slice1(start))
		self.buf.writeByte('"')
	}

	fn encodeByteSlice(mut self, s: []byte) {
		const Padding = true
		self.buf.writeByte('"')
		self.buf.write(base64::Encode(s, Padding))
		self.buf.writeByte('"')
	}

	fn encodeStruct[T, Flag](mut self, &t: T)! {
		const useIndent = comptime::TypeOf(Flag) == comptime::TypeOf(encodeIndent)
		const match {
		| useIndent:
			self.depth++
		}
		mut next := '{'
		p := uintptr(&t)
		for _, fieldCache in cachedFields[T]() {
			self.buf.writeByte(next)
			next = ','
			const match {
			| useIndent:
				self.buf.writeByte('\n')
				self.buf.writeStr(strings::Repeat(self.indent, self.depth))
			}
			if self.escapeHTML {
				self.buf.writeStr(fieldCache.nameEscHTML)
			} else {
				self.buf.writeStr(fieldCache.nameNonEsc)
			}
			const match {
			| useIndent:
				self.buf.writeByte(' ')
				fieldCache.encodeIndent(self, p+fieldCache.offset) else { error(error) }
			|:
				fieldCache.encodePlain(self, p+fieldCache.offset) else { error(error) }
			}
		}
		if next == '{' {
			self.buf.writeStr("{}")
		} else {
			const match {
			| useIndent:
				self.depth--
				self.buf.writeByte('\n')
				self.buf.writeStr(strings::Repeat(self.indent, self.depth))
			}
			self.buf.writeByte('}')
		}
	}

	fn encodeMap[T, Flag](mut self, &t: T)! {
		const tt = comptime::TypeOf(T)
		const keyT = tt.Key()
		match keyT.Kind() {
		| comptime::Str
		| comptime::Int
		| comptime::I8
		| comptime::I16
		| comptime::I32
		| comptime::I64
		| comptime::Uint
		| comptime::Uintptr
		| comptime::U8
		| comptime::U16
		| comptime::U32
		| comptime::U64:
			break
		|:
			error(&UnsupportedTypeError{Type: tt.Str()})
		}
		if t == nil {
			self.buf.writeStr("{}")
			ret
		}
		const useIndent = comptime::TypeOf(Flag) == comptime::TypeOf(encodeIndent)
		const match {
		| useIndent:
			self.depth++
		}
		comptime::TypeAlias(valueTyp, tt.Value())
		mut next := '{'
		for k, v in t {
			self.buf.writeByte(next)
			next = ','
			const match {
			| useIndent:
				self.buf.writeByte('\n')
				self.buf.writeStr(strings::Repeat(self.indent, self.depth))
			}
			// No need to check Flag. The key type cannot be/include
			// indentation-sensitive type. Look at this function's
			// implementation to see match-type conditions for the key type.
			key := resolveKeyName(k)
			self.encodeStr(key)
			self.buf.writeByte(':')
			const match {
			| useIndent:
				self.buf.writeByte(' ')
			}
			self.encode[valueTyp, Flag](v) else { error(error) }
		}
		const match {
		| useIndent:
			self.depth--
			self.buf.writeByte('\n')
			self.buf.writeStr(strings::Repeat(self.indent, self.depth))
		}
		self.buf.writeByte('}')
	}

	fn encodeArray[T, Flag](mut self, &t: T)! {
		const useIndent = comptime::TypeOf(Flag) == comptime::TypeOf(encodeIndent)
		const match {
		| useIndent:
			self.depth++
		}
		comptime::TypeAlias(valueTyp, comptime::TypeOf(t).Value())
		mut next := '['
		for _, e in t {
			self.buf.writeByte(next)
			next = ','
			const match {
			| useIndent:
				self.buf.writeByte('\n')
				self.buf.writeStr(strings::Repeat(self.indent, self.depth))
			}
			self.encode[valueTyp, Flag](e) else { error(error) }
		}
		if next == '[' {
			self.buf.writeStr("[]")
		} else {
			const match {
			| useIndent:
				self.depth--
				self.buf.writeByte('\n')
				self.buf.writeStr(strings::Repeat(self.indent, self.depth))
			}
			self.buf.writeByte(']')
		}
	}

	// Checks nil case for slices, then forwards to the [encodeArray] method.
	// Also uses base64-encoding algorithm for the []byte type.
	// Non-nil slices and arrays should have same outputs.
	fn encodeSlice[T, Flag](mut self, &t: T)! {
		if t == nil {
			self.writeStr("[]")
			ret
		}
		const match comptime::TypeOf(T).Value().Kind() {
		| comptime::U8:
			self.encodeByteSlice([]byte(t))
		|:
			self.encodeArray[T, Flag](t) else { error(error) }
		}
	}

	fn encodePlain[T, Flag](mut self, &t: T)! {
		const tt = comptime::TypeOf(T)
		const match {
		| tt.Strict() || tt.Kind() == comptime::Struct:
			// Before using the default encoding strategy, look for the custom encoder
			// methods and use it, if any. If not exist any custom encoder method,
			// fallback to default encoding.
			const for _, name in ["EncodeText"] {
				const for _, method in tt.Decl().Methods() {
					const match {
					| method.Name() == name:
						const params = method.Params()
						const match {
						| len(params) == 1 && !params[0].Mutable():
							const m = comptime::ValueOf(t).Method(method.Name())
							const match {
							| m.Type().Decl().Exceptional() &&
								m.Type().Result() == comptime::TypeOf([]byte):
								bytes := m.Unwrap()() else {
									error(&EncodeError{Type: tt.Str(), Err: error, sourceFunc: name})
								}
								const match name {
								| "EncodeText":
									self.encodeStr(unsafe::BytesStr(bytes))
								|:
									panic("std/encoding/json: unimplemented encoding method")
								}
								ret
							}
						}
					}
				}
			}
			// Fallback to the default strategy.
		}
		const match tt.Kind() {
		| comptime::Int | comptime::I8 | comptime::I16 | comptime::I32 | comptime::I64:
			self.encodeInt(i64(t))
			ret
		| comptime::Uint | comptime::U8 | comptime::U16 | comptime::U32 | comptime::U64:
			self.encodeUint(u64(t))
			ret
		| comptime::F32:
			self.encodeFloat(f64(t), 32) else { error(error) }
			ret
		| comptime::F64:
			self.encodeFloat(f64(t), 64) else { error(error) }
			ret
		| comptime::Bool:
			self.encodeBool(bool(t))
			ret
		| comptime::Str:
			self.encodeStr(str(t))
			ret
		| comptime::SmartPtr:
			// Avoid to implement as a function.
			// Fills call stack faster especially with recursive structures.
			// Handle smart pointers here efficiently and forward to relevant encoder.
			if t == nil {
				self.encodeNil()
			} else {
				comptime::TypeAlias(valueTyp, tt.Value())
				self.encode[valueTyp, Flag](*t) else { error(error) }
			}
		| comptime::Struct:
			self.encodeStruct[T, Flag](t) else { error(error) }
		| comptime::Map:
			self.encodeMap[T, Flag](t) else { error(error) }
		| comptime::Array:
			self.encodeArray[T, Flag](t) else { error(error) }
		| comptime::Slice:
			self.encodeSlice[T, Flag](t) else { error(error) }
		|:
			error(&UnsupportedTypeError{Type: tt.Str()})
		}
	}

	fn encode[T, Flag](mut self, &t: T)! {
		// Handle bind types here to avoid compile-time error messages for types.
		// The [encodePlain] should be compile-time safe for type T.
		// Prevent any compilation errors from being triggered.
		const tt = comptime::TypeOf(T)
		const match {
		| tt.Bind():
			error(&UnsupportedTypeError{Type: tt.Str()})
		|:
			self.encodePlain[T, Flag](t) else { error(error) }
		}
	}
}

// Returns jsonEncoder with default configuration.
fn encoder(): jsonEncoder {
	ret jsonEncoder{
		escapeHTML: true,
	}
}

// Implements encoding of JSON as defined in RFC 7159.
//
// The algorithm is optimized for efficiency, performance and minimum runtime.
// Uses generics and Jule's comptime. Type analysis guaranteed to be completed
// at compile-time. Also this function is no-overhead guaranteed.
// So just implements plain encoding algorithm without unnecessary
// algorithms such as indentation handling.
//
// Implementation supports only Jule types, excluding binded types.
//
// Encoding details:
//	Since this function designed for comptime type analysis, the type [T] should
//	be valid type for comptime. The type [any], which is stores dynamic type, is not valid.
//	Any unsupported type causes exceptional with [UnsupportedTypeError].
//
//	Signed/Unsigned Integers, Floating-Points:
//		Encode as JSON numbers.
//		For floating-points, NaN or ±Inf will cause exceptional with [UnsupportedValueError].
//
//	Booleans:
//		Encode as JSON booleans.
//
//	Strings:
//		Encode as JSON strings coerced to valid UTF-8, replacing invalid bytes
//		with the Unicode replacement rune. So that the JSON will be safe to embed
//		inside HTML <script> tags, the string is encoded using [HTMLEscape],
//		which replaces "<", ">", "&", U+2028, and U+2029 are escaped
//		to "\u003c", "\u003e", "\u0026", "\u2028", and "\u2029".
//
//	Structs:
//		Encode as JSON objects with only visible fields of struct.
//
//		The private and anonymous fields will be ignored.
//		If the field is public, the field name will be used.
//		If the field have a json tag, the json tag will be used even if field is private or anonymous.
//		If the field have json tag but it is duplicate, the field will be ignored.
//		A valid JSON tag must contain only Unicode letter, digit or punctuation
//		except quote chars and backslash.
//
//	Arrays:
//		Encode as JSON array.
//
//	Slices:
//		Encode as JSON array.
//		If slice is nil, encode as empty array [] JSON value.
//		For the []byte type, encodes as a base64-encoded string.
//
//	Maps:
//		Encode as JSON object.
//		If map is nil, encode as empty object {} JSON value.
//		The keys of the map always will be quoted.
//		Also map's key type only can be: signed integer, unsigned integer and string.
//		Other types will cause exceptional with [UnsupportedTypeError].
//
//	Smart Pointers:
//		If smart pointer is nil, encode as null JSON value.
//		Otherwise, will encode dereferenced value.
//
// Encode cannot represent cyclic data structures and does not handle them.
// Passing cyclic structures for encoding will result in an cycle at runtime.
// Too many nested types are not specifically checked and may cause too many
// recursive function calls, resulting in a crash at runtime. As a result of the tests,
// it is recommended that a data type can carry a maximum of 256 nested data.
//
// Supported trait implementations by higher-to-lower precedence
// (having methods without implementing the trait is valid):
//	JSONEncoder, TextEncoder
fn Encode[T](t: T)!: []byte {
	mut encoder := encoder()
	encoder.encode[T, encodePlain](t) else { error(error) }
	ret encoder.buf.bytes()
}

// Same as Encode[T] function but enables indentation.
fn EncodeIndent[T](t: T, indent: str)!: []byte {
	mut encoder := encoder()
	if indent == "" {
		encoder.encode[T, encodePlain](t) else { error(error) }
	} else {
		encoder.indent = indent
		encoder.encode[T, encodeIndent](t) else { error(error) }
	}
	ret encoder.buf.bytes()
}

// Cache data for the structure field.
struct field {
	offset:       uintptr
	nameNonEsc:   str
	nameEscHTML:  str
	encodePlain:  fn(mut &encoder: jsonEncoder, field: uintptr)!
	encodeIndent: fn(mut &encoder: jsonEncoder, field: uintptr)!
	decode:       fn(&decoder: jsonDecoder, field: uintptr)!
}

// Field cache data for structure types and associated RWMutex.
let mut fieldMap = map[uintptr][]&field{}
let mut fieldMapLock = sync::RWMutex{}

// Returns field cache data for the structure type T.
// If the structure is not cached yet, it will cache it.
fn cachedFields[T](): []&field {
	const t = comptime::TypeOf(T)
	fieldMapLock.RLock()
	mut cache, mut exist := fieldMap[t.Hash()]
	fieldMapLock.RUnlock()
	if exist {
		ret cache
	}
	// There is no cache for type type T, cache it.
	fieldMapLock.Lock()
	// Last check with write lock before cache.
	cache, exist := fieldMap[t.Hash()]
	if exist {
		fieldMapLock.Unlock()
		ret cache
	}
	p := unsafe { (*T)(0) }
	const pv = comptime::ValueOf(unsafe { *p })
	const fields = t.Fields()
	const for i, f in t.Decl().Fields() {
		const tag = f.Tag("json")
		const match {
		| f.Public() | tag != "":
			name := getFieldName[T](f.Public(), f.Name(), tag)
			if name != "" {
				comptime::TypeAlias(fieldType, fields[i].Type())

				mut fieldCache := new(field)
				fieldCache.offset = uintptr(&pv.FieldByIndex(i).Unwrap())

				// Cache name for non-escape.
				fieldCache.nameNonEsc = "\"" + name + "\":"

				// Cache name for escape-HTML.
				if isNeedHTMLEscape(unsafe::StrBytes(name)) {
					mut buf := buffer{}
					buf.writeByte('"')
					appendHTMLEscape(buf, unsafe::StrBytes(name))
					buf.writeStr("\":")
					fieldCache.nameEscHTML = unsafe::StrFromBytes(buf.bytes())
				} else {
					fieldCache.nameEscHTML = fieldCache.nameNonEsc
				}

				// Cache encoder and decoder functions.
				fieldCache.encodePlain = typeEncoderPlain[fieldType]
				fieldCache.encodeIndent = typeEncoderIndent[fieldType]
				fieldCache.decode = typeDecoder[fieldType]

				cache = append(cache, fieldCache)
			}
		}
	}
	fieldMap[t.Hash()] = cache
	fieldMapLock.Unlock()
	ret cache
}

// Reports whether the JSON tag name is duplicated.
fn isDuplicateTag[T](tag: str): bool {
	mut seen := false
	const t = comptime::TypeOf(T).Decl()
	const for _, f in t.Fields() {
		const ftag = f.Tag("json")
		if ftag != "" && ftag == tag ||
			f.Public() && f.Name() == tag {
			if seen {
				ret true
			}
			seen = true
		}
	}
	ret false
}

// Returns the JSON key name of structure field.
// If field is not public, field name will not be evaluated.
// Tries to use JSON tag name first, if tag name is not valid, falling back to field name.
// Returns empty string if field name and JSON tag name not suitable to use.
// The type T must be the structure type of field.
fn getFieldName[T](pub: bool, name: str, tag: str): str {
	// If the tag is "-", ignore this field for the JSON encode/decode.
	if tag == "-" {
		ret ""
	}
	ok := isValidTag(tag)
	// JSON tag name is not suitable to use, falling back to field name.
	// If the field is public, use the field's name, otherwise there is no name to use.
	if !ok && pub {
		ret name
	}
	// If the JSON tag name is suitable to use, check for duplicates.
	// If the key is not duplicate, use the tag name.
	if ok && !isDuplicateTag[T](tag) {
		ret tag
	}
	// No suitable name to use, return empty.
	ret ""
}

// Reports whether the JSON tag name valid.
fn isValidTag(s: str): bool {
	if s == "" {
		ret false
	}
	for _, c in s {
		if strings::ContainsRune("!#$%&()*+-./:;<=>?@[]^_{|}~ ", c) {
			// Backslash and quote chars are reserved, but
			// otherwise any punctuation chars are allowed
			// in a tag name.
		} else if !unicode::IsLetter(c) && !unicode::IsDigit(c) {
			ret false
		}
	}
	ret true
}

fn resolveKeyName[T](k: T): str {
	const t = comptime::TypeOf(T)
	const match t.Kind() {
	| comptime::Str:
		ret str(k)
	| comptime::Int | comptime::I8 | comptime::I16 | comptime::I32 | comptime::I64:
		ret conv::FormatInt(i64(k), 10)
	| comptime::Uintptr | comptime::Uint | comptime::U8 | comptime::U16 | comptime::U32 | comptime::U64:
		ret conv::FormatUint(u64(k), 10)
	}
	panic("unexpected map key type")
}

fn typeEncoderPlain[T](mut &encoder: jsonEncoder, field: uintptr)! {
	encoder.encode[T, encodePlain](unsafe { *(*T)(field) }) else { error(error) }
}

fn typeEncoderIndent[T](mut &encoder: jsonEncoder, field: uintptr)! {
	encoder.encode[T, encodeIndent](unsafe { *(*T)(field) }) else { error(error) }
}

fn typeDecoder[T](&decoder: jsonDecoder, field: uintptr)! {
	decoder.value(unsafe { *(*T)(field) }) else { error(error) }
}