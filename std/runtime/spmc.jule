// Copyright 2025 The Jule Project Contributors. All rights reserved.
// Use of this source code is governed by a BSD 3-Clause
// license that can be found in the LICENSE file.

use "std/internal/runtime/atomic"

// Bounded concurrent ring buffer for coroutines.
struct localrunq {
	head: u32
	tail: u32
	mask: u32 // cap-1
	buf:  []coro
}

impl localrunq {
	// Initializes a bounded ring buffer.
	// cap must be >= 2 and a power of two.
	fn init(mut *self, cap: int) {
		if cap < 2 || !isPowerOfTwo(cap) {
			panic("runtime: localrunq needs at least 2 and power-of-two capacity")
		}
		self.buf = make([]coro, cap)
		self.mask = u32(cap - 1)
	}

	// Enqueues one coroutine at the logical tail.
	// Single producer only.
	fn enqueue(mut *self, mut &item: *coro): bool {
		// Acquire-load head so that our full check is synchronized with
		// successful consumers that advanced head.
		h := atomic::Load(&self.head, atomic::Acquire)
		t := self.tail

		// Full if distance >= cap.
		if t-h < u32(len(self.buf)) {
			// Copy the coroutine value into the ring slot.
			// This avoids publishing a raw RC pointer slot without per-slot atomics.
			self.buf[t&self.mask] = *item

			// Publish the element. Consumers that Acquire-load tail are guaranteed
			// to observe the initialized buf slot.
			atomic::Store(&self.tail, t+1, atomic::Release)
			ret true
		}
		ret false
	}

	// Dequeues one coroutine from the logical head.
	fn dequeue(mut *self, mut &item: *coro): (ok: bool) {
		for {
			// Synchronize with producer publication and other consumers.
			h := atomic::Load(&self.head, atomic::Acquire)
			t := self.tail
			if t == h {
				ret false
			}

			// Read the slot optimistically.
			*item = self.buf[h&self.mask]

			// Claim the slot by advancing head.
			// Release here "commits" the consume after we've read the slot.
			if atomic::CompareAndSwap(&self.head, h, h+1, atomic::Release, atomic::Relaxed) {
				ret true
			}
			// CAS failed: another consumer won; retry.
		}
	}

	// Tries to steal one coroutine.
	fn steal(mut *self, mut &item: *coro): (ok: bool) {
		for {
			h := atomic::Load(&self.head, atomic::Acquire)
			t := atomic::Load(&self.tail, atomic::Acquire)

			n := t - h
			if n == 0 {
				ret false
			}

			// Must load *before* acquiring the slot as slot may be overwritten
			// immediately after acquiring. This load is NOT required to be
			// atomic even-though it may race with an overrite as we only return
			// true if we win the race below garanteeing we had no race during
			// our read. If we loose the race then `item` could be corrupt
			// due to read-during-write race but as T is trivially destructible
			// this does not matter.
			//
			// We cannot store `&coro` instead of `coro` because of the race.
			// Otherwise, RC counting may be corrupted and cause some critical
			// issues, such as use-after-free.
			*item = self.buf[h&self.mask]

			if atomic::CompareAndSwap(&self.head, h, h+1, atomic::Release, atomic::Relaxed) {
				ret true
			}
		}
	}

	// Returns an approximate size.
	fn len(*self): int {
		h := atomic::Load(&self.head, atomic::Relaxed)
		t := atomic::Load(&self.tail, atomic::Relaxed)
		n := int(t - h)
		if n < 0 {
			ret 0
		}
		ret n
	}
}