// Copyright 2024-2025 The Jule Programming Language.
// Use of this source code is governed by a BSD 3-Clause
// license that can be found in the LICENSE file.

// State flags of threads.
const threadRunning = 1 << 0
const threadSuspended = 1 << 1
const threadClosed = 1 << 2

// State flags of threads for suspend reason.
const reasonNA = 0 << 0
const reasonRecv = 1 << 3      // Channel-recv.
const reasonSend = 1 << 4      // Channel-send.
const reasonWaitGroup = 1 << 5 // WaitGroup.
const reasonMutex = 1 << 6     // Mutex kind.
const reasonCond = 1 << 7      // Condition variable.
const reasonSelect = 1 << 8    // Select statement.
const reasonStrict = 1 << 9    // See documentation of the checkDeadlock function.

// A thread instance is represents a spawned thread.
// Used by the Jule runtime to manage threads.
struct thread {
	os: osthread

	// Thread state and suspend reasons if thread is suspended.
	// The reasons may be not zeroed after thread closed or woken.
	state: u32

	// Remaining frame count of the thread for deadlock escape.
	// See documentation of the checkDeadlock function.
	frame: int

	// Unique identifier for various purposes, usually it is a pointer.
	// It used to detect a specific primitive.
	// It may be a mutex pointer for channel, of a sema pointer for mutex.
	mu: uintptr

	// Pointer to the next thread.
	// Threads stored in the thread stack with a singly linked-list.
	next: &thread
}

// Special case flags for thread management.
const threadSC_NA = 0
const threadSC_EmptySelect = 1 << 0

// A thread stack and associated lock.
// All spawned threads are stored in the threads.
// When a thread completed, it will be marked as closed.
// A closed thread instance will not be released, remains allocated and placed
// in the threads. Subsequent thread generations may use the same allocation
// of closed threads for the new spawned threads.
// threadCases stores special cases for thread management.
static threadMutex = fmutex{}
static mut threads = (&thread)(nil)
static mut threadCases = threadSC_NA

// Allocates a new thread and sets state as running.
fn newThread(): &thread {
	mut t := new(thread)
	unsafe {
		// Remove RC pointer and disable GC for thread allocations.
		// Because allocated threads will never be deallocated.
		// Avoid GC cost for threads.
		mut p := (*sptrBase[thread])(&t)
		_RCFree(p.ref)
		p.ref = nil
	}
	t.state |= threadRunning
	ret t
}

// Pushes a new thread to the main thread stack and sets state as running.
// Returns the thread representing the created thread.
// Locks the threadMutex and will not release before return,
// should be released after pushNewThread.
//
// This function assumes |threads| is not nil. So we must have a thread pointer
// associated with a thread in thread stack, it should be the main thread.
// New created threads should be added to the main thread's tail.
fn pushNewThread(): &thread {
	threadMutex.lock()
	// Lookup for empty threads to caught ready to reuse thread if exist.
	mut t := threads
	for t != nil; t = t.next {
		if t.state&threadClosed == threadClosed {
			t.state = threadRunning
			t.mu = 0
			t.frame = 0
			ret t
		}
		if t.next == nil {
			break
		}
	}
	// We have not any reusable thread, so create a new one.
	t.next = newThread()
	ret t.next
}

// Returns the thread associated with current thread.
fn getCurrentThread(): &thread {
	id := currentThreadID()
	mut t := threads
	for t != nil; t = t.next {
		if t.os.equal(id) {
			ret t
		}
	}
	ret nil
}

// Suspends the current thread and yields the CPU.
// If the mu is not zero, assumes it already locked and releases before yield.
// If reason is related with a sema, will not handle mu as a mutex.
fn yield(mu: uintptr, mut reason: u32) {
	threadMutex.lock()
	mut t := getCurrentThread()
	if t == nil {
		panic("runtime: thread is not exist")
	}
	if reason&reasonStrict == reasonStrict {
		t.frame = 4
		reason &= ^reasonStrict
	}
	t.state |= threadSuspended | reason
	t.mu = mu
	checkDeadlock(mu, reason)
	// Unlock the mutex becase other threads may need to lock.
	// There is nothing to do for this thread for now, so release lock.
	threadMutex.unlock()
	// Release mutex if reason is not related with a sema.
	if mu != 0 && reason&reasonMutex != reasonMutex && reason&reasonWaitGroup != reasonWaitGroup {
		unsafe { (*fmutex)(mu).unlock() }
	}
	// Yield the CPU if possible, it may return immediately for the same thread.
	// However, this part of thread management belongs to the operating system.
	osyield()
	// CPU is back for this thread.
	// Lock mutex again and wake up.
	threadMutex.lock()
	t.mu = 0
	t.state &= ^(threadSuspended | reason)
	threadMutex.unlock()
}

// Closes the thread associated with tptr, if exist.
fn closeThread(tptr: *unsafe) {
	threadMutex.lock()
	mut t := threads
	for t != nil; t = t.next {
		if &t.os.handle == tptr {
			// Do not reset reasons and mu field.
			// Because this kind of data may needed.
			// See the yield function for more details.
			t.state &= ^(threadRunning | threadSuspended)
			t.state |= threadClosed
			t.frame = 0
			// We have empty select special case.
			// We have to check deadlocks after any thread closed. Because at least
			// one thread is in deep sleep and we do not know when this thread will wake up.
			// So, if we have a deadlock, detection may be impossible because empty selects
			// does not checks deadlocks. So check deadlock after closed a thread to
			// caught special case deadlock; all threads are in the deep sleep.
			if threadCases&threadSC_EmptySelect == threadSC_EmptySelect {
				checkDeadlock(0, reasonNA)
			}
			threadMutex.unlock()
			break
		}
	}
}

// Checks deadlock and panics if exist.
// mut and reason is stores the current thread's parameters to yield CPU.
fn checkDeadlock(mu: uintptr, reason: u32) {
	// At this point, we should manage all threads under more diverse conditions.
	// At the end, we have do frame count analysis.
	//
	//	What is parking?
	//		A parking operation is the process of keeping a thread suspended
	//		until a specific condition is met. When a thread is suspended due to
	//		a condition, a parking operation begins. The parking ends when the
	//		thread is awakened. However, once a thread is woken up and the parking
	//		operation is completed, there is no need for the thread management
	//		system to be explicitly notified of the completion. Instead, simply
	//		indicating that a new parking operation is being initiated is enough
	//		for the system to handle the subsequent operations appropriately.
	//
	//		During a parking operation, if the condition is not met, the thread
	//		must be suspended until the next opportunity to check the condition.
	//		This can be achieved by calling the yield function appropriately.
	//		The yield function will suspend the thread, and when the thread is
	//		awakened, it will resume from where it left off. This function is
	//		also crucial for detecting deadlock situations, as it helps identify
	//		if a thread is blocked and unable to proceed due to certain conditions.
	//
	//	Typical implementation for a condition-based parking:
	//		In a typical parking implementation, the frame count should be updated
	//		before yielding. This is because a fresh yield attempt is being made,
	//		and the condition is being re-evaluated. As a result, the thread's
	//		frame count must be reset. To handle this, the reasonStrict flag
	//		should be used in every new park operation. The first yield call must
	//		include the reasonStrict flag, ensuring that the frame count is
	//		refreshed for the new condition. Subsequent yield calls should avoid
	//		using the reasonStrict flag until the condition is resolved.
	//		If reasonStrict is used repeatedly, it would initiate a new condition
	//		loop for the thread indefinitely and continuously reset the frame count.
	//
	//		For example:
	//
	//			mut reason := u32(reasonFoo | reasonStrict)
	//			for {
	//				if <condition> {
	//					ret
	//				}
	//				yield(0, reason)
	//				reason &= ^reasonStrict
	//			}
	//
	//		In the example code above, when a new condition park loop is initiated,
	//		the first yield call is made with the reasonStrict flag. This signals
	//		that a new park loop is starting and resets the thread's frame count
	//		accordingly. After that, the flag is removed, and subsequent calls
	//		are made without the flag. This ensures that the frame count remains
	//		updated until the park operation is completed, and synchronization
	//		is correctly managed throughout.
	//
	//	Frame count of threads and escape from deadlock:
	//		Frame analysis is the final phase of deadlock analysis.
	//		Each thread is assigned a frame count, which is refreshed during
	//		every new park operation. This frame count is kept optimal to ensure
	//		accurate synchronization and proper thread management.
	//
	//		Frame analysis is typically conducted as a final step after all other
	//		common conditions have been evaluated. It is used to detect deadlock
	//		situations, which may arise when threads are unable to make progress
	//		due to being stuck in suspended states, awaiting resources or conditions
	//		that cannot be met.
	//
	//		Frame analysis is based on allocating a specific number of frame chances
	//		to each thread, representing opportunities to break free from a suspended
	//		state. Each frame counts as one chance to escape the analysis.
	//		For example, a thread with 4 frame chances would undergo deadlock
	//		analysis up to 4 times, giving it 4 opportunities to move from the
	//		suspended state to a running state. If it hasn't managed to escape the
	//		suspended state during the normal analysis phase, each frame grants
	//		a chance to attempt escaping deadlock.
	//
	//		This needs to be done because sometimes, even though it may seem like
	//		a deadlock, there may actually be at least one thread that has a chance
	//		to wake up. To ensure this, each thread should be given a certain number
	//		of frames. For example, consider a condition variable.
	//		Let there be two threads: one is waiting to receive a signal,
	//		and the other is sending a signal. The thread sending the signal may
	//		finish sending the signal and terminate, but the other thread
	//		immediately goes into the waiting state afterward In this case,
	//		the normal analysis process might assume that the condition variable
	//		will never leave the waiting state because there are no other threads
	//		running. However, at this point, within the frames granted to it,
	//		the thread is considered to have a chance to wake up. Once it wakes up,
	//		it can receive the signal that was sent and exit the waiting state.
	//
	//		If a thread has exhausted all of its frame rights, its chance of
	//		waking up for that wait is considered completely nonexistent.
	//
	//	WaitGroups:
	//		If the reason is a WaitGroup, it indicates that the current thread
	//		has been suspended for a WaitGroup. At this point, we must utilize the
	//		`|wgRuns|` data. This data must satisfy the condition "`wgRuns >= 1`".
	//		The rationale for this is that only a single thread might remain
	//		at the moment, and this thread could potentially enter an infinite
	//		wait state right now. Therefore, if the frame analysis has not
	//		escaped from deadlock analysis, we must ensure that there is at least
	//		one other running thread that the WaitGroup can depend on.
	//		This guarantees that the suspended thread has a valid reason to wait
	//		and avoids potential deadlocks.
	//
	//		We cannot rely solely on frame analysis for WaitGroup because if a
	//		different thread is running, this thread can still wake up WaitGroup.
	//		However, until this happens, the WaitGroup thread may consume frames
	//		and think that it is deadlocked, so a WaitGroup should not be considered
	//		a deadlock risk as long as it is a different thread.
	//
	//		If |wgRuns| condition is not met, then start consuming the frames of
	//		the WaitGroup thread, at the end, it will be result as deadlock.
	//
	//	Condition Variables:
	//		Almost same as the WaitGroups, but condition is different.
	//		For a WaitGroup, it is sufficient to check whether all threads are
	//		in a waiting state for the same WaitGroup. However,
	//		for a condition variable, at least one thread must not be waiting for
	//		either a WaitGroup or a condition variable.
	//
	//		The reason for this difference lies in the possibility of two threads
	//		existing simultaneously—one waiting for a WaitGroup and the other for
	//		a condition variable. Even in such a scenario, the condition variable
	//		thread might wake up because a thread could have already signaled it
	//		before closed or suspended, and the thread waiting on the
	//		condition variable has not yet processed the signal. Therefore,
	//		the WaitGroup counter must also account for threads associated with
	//		condition variables. This is necessary because after a condition variable
	//		thread processes the signal, the WaitGroup wait may also conclude.
	//		However, a condition variable should not include all waiting states
	//		in its counter. A WaitGroup or another waiting condition variable
	//		cannot signal a condition variable.
	//
	//		If |condRuns| condition is not met, then start consuming the frames of
	//		the condition variable thread, at the end, it will be result as deadlock.
	//
	//	Mutexes:
	//		Mutexes are similar to WaitGroups and condition variables but differ
	//		in an important aspect: they do not add any lock states to their counters.
	//		In other words, a thread suspended due to a WaitGroup, condition variable,
	//		mutex, or select will not be included in any counters. This is because none of
	//		these suspended states can unlock the mutex being attempted.
	//
	//		It is unnecessary to exclude channel-induced suspended threads from
	//		mutex lock states. This is because a channel thread will trigger the
	//		edge case and ensure the required conditions for the channel are met,
	//		thus catching the potential deadlock.
	//
	//	Channels:
	//		Channels are checked in the same way regardless of whether they are
	//		buffered or unbuffered. Channels can enter a mutual locking state;
	//		however, this is not considered a deadlock under appropriate conditions.
	//		For example, a thread might be suspended while waiting to receive on
	//		a mutex (and therefore a channel). If no threads are actively running,
	//		all are in a suspended state—this might appear to be a deadlock.
	//		However, if another thread is suspended while waiting to send on the
	//		same channel, this situation does not constitute a deadlock.
	//		In such cases, the thread waiting to send is expected to wake up first,
	//		completing its operation and allowing the thread waiting to receive
	//		to wake up subsequently. This sequential waking ensures that the
	//		apparent deadlock resolves itself naturally without external intervention.
	//
	// 		This scenario should be considered an edge case. Under normal circumstances,
	//		channels do not require excessive attention because concurrency rarely
	//		triggers such situations. For this edge case to be triggered,
	//		the program must have advanced to the frame analysis stage.
	//
	// A quick check before heavy analysis:
	// mu is no zero and reason is mutex. For a fast check, we can try sema value.
	// If sema is not locked, mutex have a chance, so no deadlock risk.
	// It also prevents fake deadlock analysis results for mutexes.
	// For example: all threads tries to lock a mutex and they in the suspended
	// state but no one locked the mutex yet. In this case common analysis will
	// result as deadlock due to all threads suspended.
	if mu != 0 && reason&reasonMutex == reasonMutex {
		if atomicLoad(unsafe { *(*u32)(mu) }, atomicSeqCst) > 0 {
			ret
		}
	}
	mut wgRuns := 0
	mut condRuns := 0
	mut nonlocked := 0
	// Return immediately if exist any running and not suspended thread.
	// Also count the |wgRuns|, |condRuns| and |nonlocked| data at same time.
	mut t := threads
	for t != nil; t = t.next {
		if t.state&threadRunning == threadRunning {
			if t.state&threadSuspended != threadSuspended {
				// Thread is not suspended, so works.
				// No requirement for heavy analysis, return immediately.
				ret
			}
			if t.state&reasonWaitGroup != reasonWaitGroup {
				// Reason of this thread is not WaitGroup.
				// So all threads are not in the wait-state WaitGroups.
				// We can count this thread |wgRuns|.
				wgRuns++
				if t.state&reasonCond != reasonCond {
					// Reason of this thread is not WaitGroup and condition variable.
					// So all threads are not in the mutual infinite wait.
					// We can count this thread for |condRuns|.
					condRuns++
					if t.state&reasonMutex != reasonMutex && t.state&reasonSelect != reasonSelect {
						// Reason of this thread is not WaitGroup, condition variable, mutex or select.
						// So all threads are not in the mutual infinite wait or locked for a reason.
						// We can count channels because we caught channel separately.
						// So if counted channels are in the deadlock, we should caught that.
						// So we can count this thread for |nonlocked|.
						nonlocked++
					}
				}
			}
		}
	}
	// We must be count all possible |wgRuns| data here.
	// So check and return immediately if reason is WaitGroup and |wgRuns| condition met.
	// See the hard point for documentation.
	if wgRuns >= 1 && reason&reasonWaitGroup == reasonWaitGroup {
		ret
	}
	// We must be count all possible |condRuns| data here.
	// So check and return immediately if reason is condition variable and |condRuns| condition met.
	// See the hard point for documentation.
	if condRuns >= 1 && reason&reasonCond == reasonCond {
		ret
	}
	// We must be count all possible |nonlocked| data here.
	// So check and return immediately if reason is Mutex and |nonlocked| condition met.
	// See the hard point for documentation.
	if nonlocked >= 1 && reason&reasonMutex == reasonMutex {
		ret
	}
	// There is no running active thread for common cases, but we have non-zero mu.
	// So this thread associated with a channel now, we have a chance as described
	// in the channels section of the documentation. Check this edge case for a chance.
	// We have to check mutual suspended threads for channels.
	// All channels may be suspended for each other when using channels.
	// For example, a thread may be suspended for a channel-send and
	// now we may be suspend this thread for channel-recv on the same channel.
	// So two threads are suspended for each other, caught this and wake
	// suitable one. In such cases, there is no deadlock risk.
	if mu != 0 && (reason&reasonSend == reasonSend || reason&reasonRecv == reasonRecv) {
		t = threads
		for t != nil; t = t.next {
			if t.mu == mu {
				mut lt := threads
				for lt != nil; lt = lt.next {
					if lt.mu == t.mu {
						if lt.state&reasonRecv == reasonRecv &&
							t.state&reasonSend == reasonSend {
							ret
						}
						if lt.state&reasonSend == reasonSend &&
							t.state&reasonRecv == reasonRecv {
							ret
						}
					}
				}
			}
		}
	}
	// Frame analysis stage. We have to look frames of running threads as
	// described in the documentation. If any thread have a frame for this step,
	// evaluate this as running valid thread and return immediately after
	// removed a frame from thread.
	t = threads
	for t != nil; t = t.next {
		if t.state&threadRunning == threadRunning &&
			t.state&threadSuspended == threadSuspended {
			if t.frame > 0 {
				t.frame--
				ret
			}
		}
	}
	// We have not any running or ready to woken up thread, all of them suspended or closed.
	// So all threads are locked, in other words; we have a deadlock.
	panic("runtime: all threads are asleep - deadlock!")
}