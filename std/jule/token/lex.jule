// Copyright 2023-2024 The Jule Programming Language.
// Use of this source code is governed by a BSD 3-Clause
// license that can be found in the LICENSE file.

use "std/internal/strings"
use "std/jule/build"
use "std/unicode/utf8"

// Lexer mode.
enum Mode {
	Standard: 0 << 0, // Standard mode.
	Comment: 1 << 0,  // Standard mode + comments.
}

struct kindPair {
	kind: Kind
	id:   Id
}

static keywords: [...]kindPair = [
	{Kind.Const, Id.Const},
	{Kind.Ret, Id.Ret},
	{Kind.Type, Id.Type},
	{Kind.For, Id.For},
	{Kind.Break, Id.Break},
	{Kind.Cont, Id.Cont},
	{Kind.In, Id.In},
	{Kind.If, Id.If},
	{Kind.Else, Id.Else},
	{Kind.Use, Id.Use},
	{Kind.Goto, Id.Goto},
	{Kind.Enum, Id.Enum},
	{Kind.Struct, Id.Struct},
	{Kind.Co, Id.Co},
	{Kind.Match, Id.Match},
	{Kind.Self, Id.Self},
	{Kind.Trait, Id.Trait},
	{Kind.Impl, Id.Impl},
	{Kind.Cpp, Id.Cpp},
	{Kind.Fall, Id.Fall},
	{Kind.Fn, Id.Fn},
	{Kind.Let, Id.Let},
	{Kind.Unsafe, Id.Unsafe},
	{Kind.Mut, Id.Mut},
	{Kind.Defer, Id.Defer},
	{Kind.Static, Id.Static},
	{Kind.Error, Id.Error},
	{Kind.Map, Id.Map},
]

static basicOps: [...]kindPair = [
	{Kind.DblColon, Id.DblColon},
	{Kind.ColonEq, Id.ColonEq},
	{Kind.Colon, Id.Colon},
	{Kind.Semicolon, Id.Semicolon},
	{Kind.Comma, Id.Comma},
	{Kind.TripleDot, Id.TripleDot},
	{Kind.Dot, Id.Dot},
	{Kind.PlusEq, Id.PlusEq},
	{Kind.MinusEq, Id.MinusEq},
	{Kind.StarEq, Id.StarEq},
	{Kind.SolidusEq, Id.SolidusEq},
	{Kind.PercentEq, Id.PercentEq},
	{Kind.ShlEq, Id.ShlEq},
	{Kind.ShrEq, Id.ShrEq},
	{Kind.CaretEq, Id.CaretEq},
	{Kind.AmperEq, Id.AmperEq},
	{Kind.VlineEq, Id.VlineEq},
	{Kind.Eqs, Id.Eqs},
	{Kind.NotEq, Id.NotEq},
	{Kind.GtEq, Id.GtEq},
	{Kind.LtEq, Id.LtEq},
	{Kind.DblAmper, Id.DblAmper},
	{Kind.DblVline, Id.DblVline},
	{Kind.Shl, Id.Shl},
	{Kind.Shr, Id.Shr},
	{Kind.DblPlus, Id.DblPlus},
	{Kind.DblMinus, Id.DblMinus},
	{Kind.Plus, Id.Plus},
	{Kind.Minus, Id.Minus},
	{Kind.Star, Id.Star},
	{Kind.Solidus, Id.Solidus},
	{Kind.Percent, Id.Percent},
	{Kind.Amper, Id.Amper},
	{Kind.Vline, Id.Vline},
	{Kind.Caret, Id.Caret},
	{Kind.Excl, Id.Excl},
	{Kind.Lt, Id.Lt},
	{Kind.Gt, Id.Gt},
	{Kind.Eq, Id.Eq},
	{Kind.Hash, Id.Hash},
	{Kind.LBrace, Id.LBrace},
	{Kind.RBrace, Id.RBrace},
	{Kind.LBracket, Id.LBracket},
	{Kind.RBracket, Id.RBracket},
	{Kind.LParent, Id.LParent},
	{Kind.RParent, Id.RParent},
]

fn makeErr(row: int, col: int, &f: &Fileset, fmt: build::LogMsg, args: ...any): build::Log {
	ret build::Log{
		Kind: build::LogKind.Error,
		Row: row,
		Column: col,
		Path: f.Path,
		Text: build::Logf(fmt, args...),
	}
}

fn bytesHasPrefix(&bytes: []byte, prefix: str): bool {
	if len(bytes) < len(prefix) {
		ret false
	}
	for i in prefix {
		if bytes[i] != prefix[i] {
			ret false
		}
	}
	ret true
}

fn floatFmtE(&txt: []byte, mut i: int): (lit: str) {
	i++ // Skip E | e
	if i >= len(txt) {
		ret
	}

	mut b := txt[i]
	if b == '_' {
		ret
	}
	if b == '+' || b == '-' {
		i++ // Skip operator
		if i >= len(txt) {
			ret
		}
		if txt[i] == '_' {
			ret
		}
	}

	first := i
	for i < len(txt); i++ {
		b = txt[i]
		if b != '_' && !IsDecimal(b) {
			break
		}
	}

	if i == first {
		ret ""
	}
	ret str(txt[:i])
}

fn floatFmtP(&txt: []byte, i: int): str {
	ret floatFmtE(txt, i)
}

fn floatFmtDotnp(&txt: []byte, mut i: int): str {
	if txt[i] != '.' {
		ret ""
	}

	i++
loop:
	for i < len(txt); i++ {
		b := txt[i]
		match {
		| b == '_' | IsDecimal(b):
			continue
		| isFloatFmtP(b, i):
			ret floatFmtP(txt, i)
		|:
			break loop
		}
	}
	ret ""
}

fn floatFmtDotfp(&txt: []byte, mut i: int): str {
	i += 2 // skip .f
	ret floatFmtE(txt, i)
}

fn floatFmtDotp(&txt: []byte, mut i: int): str {
	i++ // skip .
	ret floatFmtE(txt, i)
}

fn floatNum(&txt: []byte, mut i: int): (lit: str) {
	i++ // Skip dot
	if i >= len(txt) {
		ret str(txt)
	}
	if txt[i] == '_' {
		i--
		ret str(txt[:i])
	}
	for i < len(txt); i++ {
		b := txt[i]
		if i > 1 && (b == 'e' || b == 'E') {
			ret floatFmtE(txt, i)
		}
		if b != '_' && !IsDecimal(b) {
			break
		}
	}

	if i == 1 { // Just dot
		ret
	}
	ret str(txt[:i])
}

fn commonNum(&txt: []byte): (lit: str) {
	mut i := 0
loop:
	for i < len(txt); i++ {
		b := txt[i]
		match {
		| b == '.':
			ret floatNum(txt, i)
		| b == '_':
			continue
		| isFloatFmtE(b, i):
			ret floatFmtE(txt, i)
		| !IsDecimal(b):
			break loop
		}
	}

	if i == 0 {
		ret
	}
	ret str(txt[:i])
}

fn binaryNum(&txt: []byte): (lit: str) {
	if !bytesHasPrefix(txt, "0b") {
		ret ""
	}
	if len(txt) < 2 {
		ret
	}

	const BinaryStart = 2
	mut i := BinaryStart
	for i < len(txt); i++ {
		if txt[i] != '_' && !IsBinary(txt[i]) {
			break
		}
	}

	if i == BinaryStart {
		ret
	}
	ret str(txt[:i])
}

fn isFloatFmtE(b: byte, i: int): bool {
	ret i > 0 && (b == 'e' || b == 'E')
}

fn isFloatFmtP(b: byte, i: int): bool {
	ret i > 0 && (b == 'p' || b == 'P')
}

fn isFloatFmtDotnp(&txt: []byte, mut i: int): bool {
	if txt[i] != '.' {
		ret false
	}
	i++
loop:
	for i < len(txt); i++ {
		b := txt[i]
		match {
		| b == '_' | IsDecimal(b):
			continue
		| isFloatFmtP(b, i):
			ret true
		|:
			break loop
		}
	}

	ret false
}

fn isFloatFmtDotp(&txt: []byte, i: int): bool {
	match {
	| len(txt) < 3:
		fall
	| txt[i] != '.':
		fall
	| txt[i+1] != 'p' && txt[i+1] != 'P':
		ret false
	|:
		ret true
	}
}

fn isFloatFmtDotfp(&txt: []byte, i: int): bool {
	match {
	| len(txt) < 4:
		fall
	| txt[i] != '.':
		fall
	| txt[i+1] != 'f' && txt[i+1] != 'F':
		fall
	| txt[i+2] != 'p' && txt[i+1] != 'P':
		ret false
	|:
		ret true
	}
}

fn octalNum(&txt: []byte): (lit: str) {
	if txt[0] != '0' {
		ret ""
	}
	if len(txt) < 2 {
		ret
	}

	mut octalStart := 1

	mut o := false
	if txt[1] == 'o' {
		if len(txt) < 3 {
			ret
		}
		octalStart++
		o = true
	}

	mut i := octalStart
	for i < len(txt); i++ {
		b := txt[i]
		if b == '.' {
			if o {
				ret ""
			}
			ret floatNum(txt, i)
		}
		if isFloatFmtE(b, i) {
			ret floatFmtE(txt, i)
		}
		if b != '_' && !IsOctal(b) {
			break
		}
	}

	if i == octalStart {
		ret
	}
	ret str(txt[:i])
}

fn hexNum(&txt: []byte): (lit: str) {
	if len(txt) < 3 {
		ret
	}
	if txt[0] != '0' || (txt[1] != 'x' && txt[1] != 'X') {
		ret
	}

	const HexStart = 2
	mut i := HexStart
loop:
	for i < len(txt); i++ {
		b := txt[i]
		match {
		| isFloatFmtDotp(txt, i):
			ret floatFmtDotp(txt, i)
		| isFloatFmtDotfp(txt, i):
			ret floatFmtDotfp(txt, i)
		| isFloatFmtP(b, i):
			ret floatFmtP(txt, i)
		| isFloatFmtDotnp(txt, i):
			ret floatFmtDotnp(txt, i)
		| b != '_' && !IsHex(b):
			break loop
		}
	}

	if i == HexStart {
		ret
	}
	ret str(txt[:i])
}

fn hexEscape(&txt: []byte, n: int): (seq: str) {
	if len(txt) < n {
		ret
	}

	const HexStart = 2
	mut i := HexStart
	for i < n; i++ {
		if !IsHex(txt[i]) {
			ret
		}
	}

	seq = str(txt[:n])
	ret
}

// Pattern (RegEx): ^\\U.{8}
fn bigUnicodePointEscape(&txt: []byte): str {
	ret hexEscape(txt, 10)
}

// Pattern (RegEx): ^\\u.{4}
fn littleUnicodePointEscape(&txt: []byte): str {
	ret hexEscape(txt, 6)
}

// Pattern (RegEx): ^\\x..
fn hexByteEscape(&txt: []byte): str {
	ret hexEscape(txt, 4)
}

// Patter (RegEx): ^\\[0-7]{3}
fn byteEscape(&txt: []byte): (seq: str) {
	if len(txt) < 4 {
		ret
	}
	if !IsOctal(txt[1]) || !IsOctal(txt[2]) || !IsOctal(txt[3]) {
		ret
	}
	ret str(txt[:4])
}

struct lex {
	mode:   Mode
	tokens: []&Token
	file:   &Fileset
	pos:    int
	column: int
	row:    int
	errors: []build::Log
}

impl lex {
	fn pushErr(mut self, fmt: build::LogMsg, args: ...any) {
		self.errors = append(self.errors,
			makeErr(self.row, self.column, self.file, fmt, args...))
	}

	fn pushErrTok(mut self, &token: &Token, fmt: build::LogMsg) {
		self.errors = append(self.errors,
			makeErr(token.Row, token.Column, self.file, fmt))
	}

	// Lexs all source content.
	fn lex(mut self) {
		self.errors = nil
		self.newLine()
		for self.pos < len(self.file.Data) {
			mut token := self.token()
			if token.Id != Id.NA {
				self.tokens = append(self.tokens, token)
			}
		}
	}

	// Returns identifer if next token is identifer,
	// returns empty string if not.
	fn id(mut self, &ln: []byte): str {
		if len(ln) == 0 {
			ret ""
		}
		r, mut i := utf8::DecodeRune(ln)
		if r != '_' && !IsLetter(r) {
			ret ""
		}

		for i < len(ln) {
			pr, n := utf8::DecodeRune(ln[i:])
			if pr != '_' && !IsDecimal(byte(pr)) && !IsLetter(pr) {
				self.pos += i
				ret str(ln[:i])
			}
			i += n
		}

		self.pos += len(ln)
		ret str(ln)
	}

	// Resume to lex from position.
	fn resume(mut self): []byte {
		// Skip spaces.
		mut i := self.pos
		for i < len(self.file.Data); i++ {
			r := rune(self.file.Data[i])
			if IsSpace(r) {
				self.pos++
				match r {
				| '\n':
					self.newLine()
				|:
					self.column++
				}
				continue
			}

			mut j := i
			for j < len(self.file.Data); j++ {
				if self.file.Data[j] == '\n' {
					break
				}
			}
			ret self.file.Data[i:j]
		}
		ret nil
	}

	fn lexLineComment(mut self, mut &token: &Token) {
		start := self.pos
		self.pos += 2
		for self.pos < len(self.file.Data); self.pos++ {
			r := self.file.Data[self.pos]
			if r == '\n' || r == '\r' {
				break
			}
		}
		if self.mode&Mode.Comment == Mode.Comment {
			token.Id = Id.Comment
			token.Kind = str(self.file.Data[start:self.pos])
		}
	}

	fn lexRangeComment(mut self, mut &token: &Token) {
		start := self.pos
		self.pos += 2
		for self.pos < len(self.file.Data); self.pos++ {
			r := self.file.Data[self.pos]
			if r == '\r' {
				continue
			}
			if r == '\n' {
				self.newLine()
				continue
			}
			self.column += 1
			if self.pos+1 < len(self.file.Data) && r == '*' &&
				self.file.Data[self.pos+1] == '/' {
				self.column += 2
				self.pos += 2
				if self.mode&Mode.Comment == Mode.Comment {
					token.Id = Id.Comment
					token.Kind = str(self.file.Data[start:self.pos])
				}
				ret
			}
		}
		self.pushErr(build::LogMsg.MissingBlockCommentClose)
	}

	// Returns literal if next token is numeric, returns empty string if not.
	fn num(mut self, &txt: []byte): (lit: str) {
		if txt[0] == '_' {
			ret ""
		}
		lit = hexNum(txt)
		if lit != "" {
			goto end
		}
		lit = octalNum(txt)
		if lit != "" {
			goto end
		}
		lit = binaryNum(txt)
		if lit != "" {
			goto end
		}
		lit = commonNum(txt)
	end:
		self.pos += len(lit)
		ret
	}

	fn escapeSeq(mut self, &txt: []byte): str {
		mut seq := ""
		if len(txt) < 2 {
			goto end
		}

		match txt[1] {
		| '\\' | '\'' | '"' | 'a' | 'b' | 'f' | 'n' | 'r' | 't' | 'v':
			self.pos += 2
			ret str(txt[:2])
		| 'U':
			seq = bigUnicodePointEscape(txt)
		| 'u':
			seq = littleUnicodePointEscape(txt)
		| 'x':
			seq = hexByteEscape(txt)
		|:
			seq = byteEscape(txt)
		}

	end:
		if seq == "" {
			self.pos++
			self.pushErr(build::LogMsg.InvalidEscapeSeq)
			ret ""
		}
		self.pos += len(seq)
		ret seq
	}

	fn getRune(mut self, &txt: []byte, raw: bool): str {
		if !raw && txt[0] == '\\' {
			ret self.escapeSeq(txt)
		}
		r, n := utf8::DecodeRune(txt)
		self.pos += n
		ret str(r)
	}

	fn lexRune(mut self, &txt: []byte): str {
		mut run := strings::Builder.New(1 << 3)
		run.WriteByte('\'')
		self.column++
		mut n := 0
		mut i := 1
		for i < len(txt); i++ {
			if txt[i] == '\r' {
				continue
			}
			if txt[i] == '\n' {
				self.pushErr(build::LogMsg.MissingRuneEnd)
				self.pos++
				self.newLine()
				ret ""
			}

			part := txt[i:]
			r := self.getRune(part, false)
			run.WriteStr(r)
			self.column += utf8::RuneCountStr(r)
			if r == "'" {
				self.pos++
				break
			}
			if len(r) > 1 {
				i += len(r) - 1
			}
			n++
		}

		if n == 0 {
			self.pushErr(build::LogMsg.RuneEmpty)
		} else if n > 1 {
			self.pushErr(build::LogMsg.RuneOverflow)
		}

		ret run.Str()
	}

	fn lexStr(mut self): str {
		mut s := strings::Builder.New(1 << 4)
		mark := self.file.Data[self.pos]
		self.pos++ // Skip mark
		raw := mark == '`'
		s.WriteByte(mark)
		self.column++

		for self.pos < len(self.file.Data) {
			ch := self.file.Data[self.pos]
			if ch == '\r' {
				continue
			}
			if ch == '\n' {
				self.newLine()
				if !raw {
					self.pushErr(build::LogMsg.MissingStrEnd)
					self.pos++
					ret ""
				}
			}
			mut part := self.file.Data[self.pos:]
			r := self.getRune(part, raw)
			s.WriteStr(r)
			self.column += utf8::RuneCountStr(r)
			if ch == mark {
				break
			}
		}

		ret s.Str()
	}

	fn isFirstTokenOfLine(self): bool {
		ret self.column == 1
	}

	fn newLine(mut self) {
		self.row++
		self.column = 1
	}

	fn isOp(mut self, &txt: []byte, kind: str, id: Id, mut &t: &Token): bool {
		if !bytesHasPrefix(txt, kind) {
			ret false
		}
		t.Kind = kind
		t.Id = id
		self.pos += len(kind)
		ret true
	}

	fn lexBasicOps(mut self, txt: []byte, mut &tok: &Token): bool {
		for _, pair in basicOps {
			if self.isOp(txt, pair.kind, pair.id, tok) {
				ret true
			}
		}
		ret false
	}

	fn lexId(mut self, &txt: []byte, mut &t: &Token): bool {
		lex := self.id(txt)
		if lex == "" {
			ret false
		}
		t.Kind = lex
		t.Id = Id.Ident
		ret true
	}

	fn lexNum(mut self, &txt: []byte, mut &t: &Token): bool {
		lex := self.num(txt)
		if lex == "" {
			ret false
		}
		t.Kind = lex
		t.Id = Id.Lit
		ret true
	}

	// lex.Token generates next token from resume at position.
	fn token(mut self): &Token {
		mut t := &Token{
			File: self.file,
			Id: Id.NA,
		}

		txt := self.resume()
		if txt == nil {
			ret t
		}

		// Set token values.
		t.Column = self.column
		t.Row = self.row

		//* lex.Tokenenize
		match {
		| self.lexNum(txt, t):
			// Pass.
			break
		| txt[0] == '\'':
			t.Kind = self.lexRune(txt)
			t.Id = Id.Lit
			ret t
		| txt[0] == '"' || txt[0] == '`':
			t.Kind = self.lexStr()
			t.Id = Id.Lit
			ret t
		| bytesHasPrefix(txt, Kind.LnComment):
			self.lexLineComment(t)
			ret t
		| bytesHasPrefix(txt, Kind.RangLComment):
			self.lexRangeComment(t)
			ret t
		| self.lexBasicOps(txt, t):
			// Pass.
			break
		| self.lexId(txt, t):
			for _, pair in keywords {
				if pair.kind == t.Kind {
					t.Id = pair.id
					break
				}
			}
		|:
			r, sz := utf8::DecodeRune(txt)
			self.pushErr(build::LogMsg.InvalidToken, r)
			self.column++
			self.pos += sz
			ret t
		}
		self.column += utf8::RuneCountStr(t.Kind)
		ret t
	}
}

// Lex source code into fileset.
// Returns nil if f == nil.
// Returns nil slice for errors if no any error.
fn Lex(mut f: &Fileset, mode: Mode): []build::Log {
	if f == nil {
		ret nil
	}

	mut lex := lex{
		mode: mode,
		file: f,
		pos: 0,
		row: -1, // For true row 
	}

	lex.newLine()
	lex.lex()

	if len(lex.errors) > 0 {
		ret lex.errors
	}

	f.Tokens = lex.tokens
	ret nil
}