// Copyright 2023 The Jule Project Contributors. All rights reserved.
// Use of this source code is governed by a BSD 3-Clause
// license that can be found in the LICENSE file.

use "julec/env"
use "julec/obj"
use "julec/obj/meta"
use "julec/opt"
use "std/conv"
use "std/jule/constant"
use "std/jule/directive"
use "std/jule/sema"
use "std/jule/token"
use "std/jule/types"
use "std/runtime"
use "std/strings"
use "std/unsafe"

const (
	closureCtxIdent  = "__jule_closure_ctx"
	matchExpr        = "_match_expr"
	resultName       = "__jule_func_result"
	assignResultName = "__jule_assign_result"
	resultArgName    = "__jule_result_arg"
)

let assignArgName = "__jule_assign_arg"

// Common group of semantic analysis stmt types and optimizer specific types.
enum compStmt: type {
	sema::Stmt,
	&opt::PushToSliceExpr,
	&opt::MutSlicingExpr,
	&opt::SwapExpr,
	&opt::ExceptionalForwardingExpr,
	&opt::StrRuneIter,
}

// Channel and case hash for select.
struct chanCase {
	Case:  &sema::Case
	Value: &sema::Value
}

struct scopeCoder {
	oc: &ObjectCoder

	deferredScopes: []&sema::Scope

	// Masks memory addresses with a specific value.
	// In this way, identical code blocks can be duplicated.
	// This is particularly useful for defer scopes,
	// because defer scopes may be written multiple times within the same function block.
	// To prevent scopes from redefining the same addresses and to avoid conflicts,
	// they use this value in the address mapping.
	// As a result, the risk of collision is eliminated.
	addrmap: map[uintptr]uintptr
}

impl scopeCoder {
	fn new(mut oc: &ObjectCoder): &scopeCoder {
		ret &scopeCoder{
			oc: oc,
			addrmap: make(map[uintptr]uintptr, 256),
		}
	}

	// Registers addr to addrmap and returns the corresponding addrmap value.
	fn registerAddrmap(mut &self, addr: uintptr): uintptr {
		self.addrmap[addr]++
		addrmap := self.addrmap[addr]
		if addrmap == 0 {
			panic("project is too large for the current architecture: " + runtime::Arch)
		}
		ret addrmap
	}

	// Returns the corresponding addrmap value by addr.
	fn getAddrmap(mut &self, addr: uintptr): uintptr {
		mut addrmap := self.addrmap[addr]
		// addrmap is zero, this addr is not mapped yet.
		// But it should be in the future, so handle it with 1.
		if addrmap == 0 {
			addrmap = 1
		}
		ret addrmap
	}

	fn rangeChanIter(mut &self, mut it: &sema::RangeIter) {
		self.oc.write("{\n")
		self.oc.addIndent()
		self.oc.indent()
		self.oc.write("auto expr = ")
		mut ref := false
		if opt::Copy && isCopyOptimizable(it.Expr, true) {
			ref = true
			self.oc.write("&(")
			self.oc.ec.model(it.Expr.Model)
			self.oc.write(")")
		} else {
			self.oc.ec.possibleRefExpr(it.Expr.Model)
		}
		self.oc.write(";\n")
		mut sb := strings::Builder{}
		addrmap := self.registerAddrmap(uintptr(it))
		identCoder.iterNext(&sb, uintptr(it), addrmap)
		next := sb.Str()
		self.oc.write(next)
		self.oc.write(":;\n")
		self.oc.indent()
		self.oc.write(typeBool + " __ok = false;\n")
		self.oc.indent()
		writeExpr := fn() {
			// Write channel receive expression.
			// Use built-in expression for that.
			// sb should be cleared, make sure content is used already.
			sb.Clear()
			if ref {
				sb.WriteByte('*')!
			}
			sb.WriteStr("expr")!
			model := any(sb.Str())
			mut expr := new(sema::ChanRecv)
			expr.Token = it.ExprToken
			expr.Expr = new(sema::Value)
			expr.Expr.Type = it.Expr.Type
			expr.Expr.Model = unsafe { *(*sema::Expr)(&model) }
			self.oc.ec.chanRecv(expr, fn|| self.oc.write("&__ok"))
		}
		if it.KeyA != nil {
			self.oc.varInitExpr(it.KeyA, writeExpr)
		} else {
			writeExpr()
			self.oc.write(";")
		}
		self.oc.write("\n")
		self.oc.indent()
		self.oc.write("if (__ok) {\n")
		self.oc.addIndent()
		self.oc.indent()
		self.scope(it.Scope)
		self.oc.write("\n")
		self.oc.indent()
		self.oc.write("goto ")
		self.oc.write(next)
		self.oc.write(";\n")
		self.oc.doneIndent()
		self.oc.indent()
		self.oc.write("}\n")

		// Close scope.
		self.oc.indent()
		identCoder.iterEnd(&self.oc.Buf, uintptr(it), addrmap)
		self.oc.write(":;\n")
		self.oc.doneIndent()
		self.oc.indent()
		self.oc.write("}")
	}

	// Common head object-code for iterations of all kind.
	fn iterHead(mut &self, mut it: &sema::RangeIter, mut &ref: *bool, begin: str) {
		self.oc.write("{\n")
		self.oc.addIndent()
		self.oc.indent()
		self.oc.write("auto expr = ")
		if opt::Copy && isCopyOptimizable(it.Expr, true) {
			*ref = true
			self.oc.write("&(")
			self.oc.ec.model(it.Expr.Model)
			self.oc.write(")")
		} else {
			self.oc.ec.possibleRefExpr(it.Expr.Model)
		}
		self.oc.write(";\n")
		self.oc.indent()
		self.oc.write("auto it = expr")
		if *ref {
			self.oc.write("->")
		} else {
			self.oc.write(".")
		}
		self.oc.write("begin();\n")
		self.oc.indent()
		self.oc.write("auto expr_end = expr")
		if *ref {
			self.oc.write("->")
		} else {
			self.oc.write(".")
		}
		self.oc.write("end();\n")
		self.oc.indent()
		self.oc.write(begin)
		self.oc.write(":;\n")
		self.oc.indent()
		self.oc.write("if (it != expr_end) {\n")
		self.oc.addIndent()
		self.oc.indent()
	}

	fn rangeIndexIter(mut &self, mut it: &sema::RangeIter) {
		mut sb := strings::Builder{}
		addrmap := self.registerAddrmap(uintptr(it))
		identCoder.iterBegin(&sb, uintptr(it), addrmap)
		begin := sb.Str()
		sb.Clear()
		identCoder.iterNext(&sb, uintptr(it), addrmap)
		next := sb.Str()

		mut ref := false
		self.iterHead(it, &ref, begin)
		if it.KeyA != nil {
			self.oc.varInitExpr(it.KeyA, fn|| {
				if ref {
					self.oc.write("it - expr->begin()")
				} else {
					self.oc.write("it - expr.begin()")
				}
			})
			self.oc.write("\n")
			self.oc.indent()
		}
		// The index of the varPrefix, generated for the optimzied output of the KeyB.
		// If the variable did not generated, value is -1.
		mut optimizedVarPrefixForKeyB := -1
		defer {
			if optimizedVarPrefixForKeyB != -1 {
				// Remove the prefix for optimized output for the KeyB.
				self.oc.ec.varPrefixes = append(
					self.oc.ec.varPrefixes[:optimizedVarPrefixForKeyB],
					self.oc.ec.varPrefixes[optimizedVarPrefixForKeyB+1:]...)
			}
		}
		if it.KeyB != nil {
			// Save the original type of the variable, then restore it.
			// Because copy optimization may update the type, which can lead compile errors.
			// Closures, for example. When generating the closure data,
			// the captured variable types must be correct.
			// Otherwise, it may handled as optimized type for copy optimization.
			mut originType := it.KeyB.TypeSym.Type

			copyOptimizable := opt::Copy && isIterCopyOptimizable(it.Expr, it.KeyB)
			if copyOptimizable {
				it.KeyB.TypeSym.Type = &sema::Type{
					Kind: &sema::Ptr{
						Value: it.KeyB.TypeSym.Type,
					},
				}
				mut keyBIdent := strings::Builder{}
				keyBIdent.WriteStr("(*")!
				identCoder.var(&keyBIdent, it.KeyB)
				keyBIdent.WriteByte(')')!
				name := keyBIdent.Str()
				optimizedVarPrefixForKeyB = len(self.oc.ec.varPrefixes)
				self.oc.ec.varPrefixes = append(self.oc.ec.varPrefixes, fn|v| {
					if v == it.KeyB {
						self.oc.write(name)
						ret true
					}
					ret false
				})
			}
			self.oc.varInitExpr(it.KeyB, fn|| {
				unsafe {
					if copyOptimizable {
						self.oc.write("it")
					} else {
						self.oc.write("*it")
					}
				}
			})
			it.KeyB.TypeSym.Type = originType
			self.oc.write("\n")
			self.oc.indent()
		}
		self.scope(it.Scope)
		self.oc.write("\n")
		self.oc.indent()
		self.oc.write(next)
		self.oc.write(":;\n")
		self.oc.indent()
		self.oc.write("++it;\n")
		self.oc.indent()
		if it.KeyA != nil {
			identCoder.var(&self.oc.Buf, it.KeyA)
			self.oc.write("++;\n")
			self.oc.indent()
		}
		self.oc.write("goto ")
		self.oc.write(begin)
		self.oc.write(";\n")

		// Close if.
		self.oc.doneIndent()
		self.oc.indent()
		self.oc.write("}\n")

		self.oc.indent()
		identCoder.iterEnd(&self.oc.Buf, uintptr(it), addrmap)
		self.oc.write(":;\n")

		// Close scope.
		self.oc.doneIndent()
		self.oc.indent()
		self.oc.write("}")
	}

	fn rangeHashmapIter(mut &self, mut it: &sema::RangeIter) {
		mut sb := strings::Builder{}
		addrmap := self.registerAddrmap(uintptr(it))
		identCoder.iterBegin(&sb, uintptr(it), addrmap)
		begin := sb.Str()
		sb.Clear()
		identCoder.iterNext(&sb, uintptr(it), addrmap)
		next := sb.Str()

		mut _map := it.Expr.Type.Map()
		mut ins := obj::FindStructGenericInstance(meta::Program.Runtime.Map, _map.Key, _map.Value)
		const Static = false
		mut f := ins.FindMethod("iterator", Static).Instances[0]

		mut iterator := obj::FindStructGenericInstance(meta::Program.Runtime.MapIterator, _map.Key, _map.Value)
		mut nextCall := iterator.FindMethod("next", Static).Instances[0]

		const (
			resultName    = "__iterator_result"
			resultArgName = resultName + "." + resultArgName
			resultKey     = resultArgName + "0"
			resultVal     = resultArgName + "1"
		)

		self.oc.write("{\n")
		self.oc.addIndent()
		self.oc.indent()
		self.oc.tc.structureIns(&self.oc.Buf, iterator)
		self.oc.write(" it = ")
		identCoder.funcIns(&self.oc.Buf, f)
		self.oc.write("(")
		self.oc.ec.possibleRefExpr(it.Expr.Model)
		self.oc.write(");\n")
		self.oc.indent()
		self.oc.write(begin)
		self.oc.write(":;\n")
		self.oc.indent()
		self.oc.tc.funcInsResult(&self.oc.Buf, nextCall)
		self.oc.write(" ")
		self.oc.write(resultName)
		self.oc.write(" = ")
		identCoder.funcIns(&self.oc.Buf, nextCall)
		self.oc.write("(&it);\n")
		self.oc.indent()
		self.oc.write("if (")
		self.oc.write(resultKey)
		self.oc.write(" != nullptr) {\n")
		self.oc.addIndent()
		self.oc.indent()
		if it.KeyA != nil {
			self.oc.varInitExpr(it.KeyA, fn|| self.oc.write("*"+resultKey))
			self.oc.write("\n")
			self.oc.indent()
		}
		if it.KeyB != nil {
			self.oc.varInitExpr(it.KeyB, fn|| self.oc.write("*"+resultVal))
			self.oc.write("\n")
			self.oc.indent()
		}
		self.scope(it.Scope)
		self.oc.write("\n")
		self.oc.indent()
		self.oc.write(next)
		self.oc.write(":;\n")
		self.oc.indent()
		self.oc.write("goto ")
		self.oc.write(begin)
		self.oc.write(";\n")

		// Close if.
		self.oc.doneIndent()
		self.oc.indent()
		self.oc.write("}\n")

		self.oc.indent()
		identCoder.iterEnd(&self.oc.Buf, uintptr(it), addrmap)
		self.oc.write(":;\n")

		// Close scope.
		self.oc.doneIndent()
		self.oc.indent()
		self.oc.write("}")
	}

	fn strRuneIter(mut &self, mut it: opt::StrRuneIter, utf8: bool) {
		mut sb := strings::Builder{}
		addrmap := self.registerAddrmap(uintptr(it.Base))
		identCoder.iterBegin(&sb, uintptr(it.Base), addrmap)
		begin := sb.Str()
		sb.Clear()
		identCoder.iterNext(&sb, uintptr(it.Base), addrmap)
		next := sb.Str()

		self.oc.write("{\n")
		self.oc.addIndent()
		self.oc.indent()

		mut ref := false
		self.oc.write("auto expr = ")
		if opt::Copy && isCopyOptimizable(it.Expr, true) {
			ref = true
			self.oc.write("&(")
			self.oc.ec.model(it.Expr.Model)
			self.oc.write(")")
		} else {
			self.oc.ec.possibleRefExpr(it.Expr.Model)
		}
		self.oc.write(";\n")
		self.oc.indent()
		self.oc.write(typeU8)
		self.oc.write(" *it = expr")
		if ref {
			self.oc.write("->")
		} else {
			self.oc.write(".")
		}
		self.oc.write("begin();\n")
		self.oc.indent()
		self.oc.write("const ")
		self.oc.write(typeU8)
		self.oc.write(" *end = it + expr")
		if ref {
			self.oc.write("->")
		} else {
			self.oc.write(".")
		}
		self.oc.write("len();\n")
		self.oc.indent()

		// Variables.
		if it.Base.KeyA != nil {
			self.oc.varInitExpr(it.Base.KeyA, fn|| self.oc.write("0"))
			self.oc.write("\n")
			self.oc.indent()
		}
		self.oc.write(typeInt)
		self.oc.write(" len;\n")
		self.oc.indent()
		if it.Base.KeyB != nil {
			self.oc.varInitExpr(it.Base.KeyB, nil)
			self.oc.write("\n")
			self.oc.indent()
		}
		self.oc.write(begin)
		self.oc.write(":;\n")
		self.oc.indent()
		self.oc.write("__jule_runeStep(it, end - it, ")
		if it.Base.KeyB != nil {
			self.oc.write("&")
			identCoder.var(&self.oc.Buf, it.Base.KeyB)
		} else {
			self.oc.write("nullptr")
		}
		self.oc.write(", &len);\n")
		self.oc.indent()

		self.oc.write("if (it < end) {\n")
		self.oc.addIndent()
		self.oc.indent()
		self.scope(it.Base.Scope)
		self.oc.write("\n")
		self.oc.indent()
		self.oc.write(next)
		self.oc.write(":;\n")
		self.oc.indent()
		self.oc.write("it += len;\n")
		self.oc.indent()
		if it.Base.KeyA != nil {
			identCoder.var(&self.oc.Buf, it.Base.KeyA)
			if utf8 {
				self.oc.write(" += len;\n")
			} else {
				self.oc.write("++;\n")
			}
			self.oc.indent()
		}
		self.oc.write("goto ")
		self.oc.write(begin)
		self.oc.write(";\n")

		// Close if.
		self.oc.doneIndent()
		self.oc.indent()
		self.oc.write("}\n")

		self.oc.indent()
		identCoder.iterEnd(&self.oc.Buf, uintptr(it.Base), addrmap)
		self.oc.write(":;\n")

		// Close scope.
		self.oc.doneIndent()
		self.oc.indent()
		self.oc.write("}")
	}

	fn conditional(mut &self, mut c: &sema::Conditional) {
		addrmap := self.registerAddrmap(uintptr(c))

		self.oc.write("{\n")
		self.oc.addIndent()
		self.oc.indent()
		self.oc.write(typeBool)
		self.oc.write(" x;\n")
		for (_, mut case) in c.Elifs {
			if case == nil {
				continue
			}
			self.oc.indent()
			self.oc.write("{\n")
			self.oc.addIndent()
			self.oc.indent()
			self.oc.write("x = ")
			self.oc.ec.possibleRefExpr(case.Expr)
			self.oc.write(";\n")
			self.oc.indent()
			self.oc.write("if (x) {\n")
			self.oc.addIndent()
			self.oc.indent()
			self.scope(case.Scope)
			self.oc.write("\n")
			self.oc.indent()
			self.oc.write("goto ")
			identCoder.matchEnd(&self.oc.Buf, uintptr(c), addrmap)
			self.oc.write(";\n")
			self.oc.doneIndent()
			self.oc.indent()
			self.oc.write("}\n")
			self.oc.doneIndent()
			self.oc.indent()
			self.oc.write("}\n")
		}
		if c.Default != nil {
			self.oc.indent()
			self.scope(c.Default.Scope)
			self.oc.write("\n")
		}
		self.oc.indent()
		identCoder.matchEnd(&self.oc.Buf, uintptr(c), addrmap)
		self.oc.write(":;\n")
		self.oc.doneIndent()
		self.oc.indent()
		self.oc.write("}")
	}

	fn infIter(mut &self, mut it: &sema::InfIter) {
		self.oc.write("for (;;) {\n")
		self.oc.addIndent() // Indent scope.
		self.oc.indent()

		// For async runtime, we need to add a compiler barrier here.
		if self.oc.mode&_OBJ_ASYNC == _OBJ_ASYNC {
			self.oc.write(compilerBarrier)
			self.oc.write(";\n")
			self.oc.indent()
		}

		addrmap := self.registerAddrmap(uintptr(it))

		self.scope(it.Scope)
		self.oc.doneIndent()
		self.oc.write("\n")
		self.oc.indent()
		identCoder.iterNext(&self.oc.Buf, uintptr(it), addrmap)
		self.oc.write(":;\n")
		self.oc.indent()
		self.oc.write("}\n")
		self.oc.indent()
		identCoder.iterEnd(&self.oc.Buf, uintptr(it), addrmap)
		self.oc.write(":;")
	}

	fn whileIter(mut &self, mut it: &sema::WhileIter) {
		mut sb := strings::Builder{}
		addrmap := self.registerAddrmap(uintptr(it))
		identCoder.iterBegin(&sb, uintptr(it), addrmap)
		begin := sb.Str()
		sb.Clear()
		identCoder.iterNext(&sb, uintptr(it), addrmap)
		next := sb.Str()
		itaddr := conv::FormatUint(u64(uintptr(it)), 16)

		self.oc.write("{\n")
		self.oc.addIndent()
		self.oc.indent()

		self.oc.write(begin)
		self.oc.write(":;\n")
		self.oc.indent()

		// For async runtime, we need to add a compiler barrier here.
		if self.oc.mode&_OBJ_ASYNC == _OBJ_ASYNC {
			self.oc.write(compilerBarrier)
			self.oc.write(";\n")
			self.oc.indent()
		}

		if it.Expr != nil {
			self.oc.write(typeBool)
			self.oc.write(" _")
			self.oc.write(itaddr)
			self.oc.write("_expr = ")
			self.oc.ec.possibleRefExpr(it.Expr)
			self.oc.write(";\n")
			self.oc.indent()
			self.oc.write("if (_")
			self.oc.write(itaddr)
			self.oc.write("_expr) {\n")
			self.oc.addIndent()
			self.oc.indent()
		}

		self.scope(it.Scope)
		self.oc.write("\n")
		self.oc.indent()

		self.oc.write(next)
		self.oc.write(":;\n")
		self.oc.indent()

		if it.Next != nil {
			self.st(it.Next)
			self.oc.write(";\n")
			self.oc.indent()
		}

		self.oc.write("goto ")
		self.oc.write(begin)
		self.oc.write(";\n")

		if it.Expr != nil {
			self.oc.doneIndent()
			self.oc.indent()
			self.oc.write("}\n")
		}
		self.oc.indent()

		identCoder.iterEnd(&self.oc.Buf, uintptr(it), addrmap)
		self.oc.write(":;\n")

		// Close scope.
		self.oc.doneIndent()
		self.oc.indent()
		self.oc.write("}")
	}

	fn rangeIter(mut &self, mut it: &sema::RangeIter) {
		match {
		| it.Expr.Type.Chan() != nil:
			self.rangeChanIter(it)
		| it.Expr.Type.Slice() != nil:
			self.rangeIndexIter(it)
		| it.Expr.Type.Array() != nil:
			self.rangeIndexIter(it)
		| it.Expr.Type.Map() != nil:
			self.rangeHashmapIter(it)
		|:
			mut sit := opt::StrRuneIter{Expr: it.Expr, Base: it}
			self.strRuneIter(sit, true) // Str
		}
	}

	fn continueStmt(mut &self, c: &sema::Continue) {
		mut childIndex := unsafe { (*(*&sema::Scope)(c.It)).ChildIndex }
		childIndex++
		self.emitDefersByLevel(childIndex, false)
		self.oc.write("goto ")
		identCoder.iterNext(&self.oc.Buf, c.It, self.getAddrmap(c.It))
	}

	fn label(mut &self, l: &sema::Label) {
		addrmap := self.registerAddrmap(uintptr(l))
		identCoder.label(&self.oc.Buf, uintptr(l), addrmap)
		self.oc.write(":")

		// For async runtime, we need to add a compiler barrier here.
		if self.oc.mode&_OBJ_ASYNC == _OBJ_ASYNC {
			self.oc.write("; ")
			self.oc.write(compilerBarrier)
		}
	}

	fn gotoStmt(mut &self, gt: &sema::Goto) {
		// Emits deferred scopes, if jumps to a parent scope.
		mut childIndex := unsafe { (*sema::Label)(gt.Label).Scope.ChildIndex }
		if gt.Scope.ChildIndex > childIndex {
			childIndex += 2
			self.emitDefersByLevel(childIndex, false)
		}

		self.oc.write("goto ")
		identCoder.label(&self.oc.Buf, uintptr(gt.Label), self.getAddrmap(uintptr(gt.Label)))
	}

	fn tryMapSet(mut &self, mut m: compExpr): (ok: bool) {
		mut iem, ok := m.(&sema::IndexingExpr)
		if !ok {
			ret
		}
		_map := iem.Expr.Type.Map()
		if _map == nil {
			ret false
		}
		// Map indexing used for assignment.
		// Generate direct lookup unlike expression coder.
		mut ins := obj::FindStructGenericInstance(meta::Program.Runtime.Map, _map.Key, _map.Value)
		const Static = false
		mut f := ins.FindMethod("set", Static).Instances[0]
		self.oc.write("(*")
		identCoder.funcIns(&self.oc.Buf, f)
		self.oc.write("((")
		self.oc.ec.possibleRefExpr(iem.Expr.Model)
		self.oc.write(").must_ok(\"")
		self.oc.locInfo(iem.Token)
		self.oc.write("\").alloc, ")
		self.oc.ec.possibleRefExpr(iem.Index.Model)
		self.oc.write("))")
		ret
	}

	fn postfix(mut &self, mut p: &sema::Postfix) {
		self.oc.write("(")
		ok := self.tryMapSet(p.Expr)
		if !ok {
			self.oc.ec.possibleRefExpr(p.Expr)
		}
		self.oc.write(")")
		self.oc.write(p.Op)
	}

	fn assignLeft(mut &self, mut model: compExpr) {
		ok := self.tryMapSet(model)
		if !ok {
			self.oc.ec.possibleRefExpr(model)
		}
	}

	fn shl(mut &self, mut l: compExpr, mut lt: &sema::Type, mut r: compExpr, mut rt: &sema::Type) {
		self.assignLeft(l)
		self.oc.write(" = ")
		self.oc.ec.shl(l, lt, r, rt)
	}

	fn shr(mut &self, mut l: compExpr, mut lt: &sema::Type, mut r: compExpr, mut rt: &sema::Type) {
		self.assignLeft(l)
		self.oc.write(" = ")
		self.oc.ec.shr(l, lt, r, rt)
	}

	fn divByZeroAssign(mut &self, loc: &token::Token, opID: int, mut l: compExpr, mut lt: &sema::Type, mut r: compExpr, mut rt: &sema::Type) {
		self.assignLeft(l)
		self.oc.write(" = ")
		self.oc.ec.divByZeroBinary(loc, opID, l, lt, r, rt)
	}

	fn cmplxAssign(mut &self, opID: int, opKind: str, mut l: compExpr, mut lt: &sema::Type, mut r: compExpr, mut rt: &sema::Type, kind: str) {
		mut fc := isExceptionalResult(r)
		if opID == token::ASSIGN && fc != nil {
			self.oc.ec.handleExceptionalCallWithData(fc, useExprMemory{
				Loc: nil,
				DestType: lt,
				Model: l,
				Type: useExprAssignment,
				OpID: opID,
				OpKind: opKind,
			})
			ret
		}

		// Build necessary temporary variable.
		if fc != nil {
			self.oc.addIndent()
			self.oc.write("{\n")
			self.oc.indent()
			self.oc.tc.kind(&self.oc.Buf, rt)
			self.oc.write(" __cmplx_temp;")
			self.oc.ec.handleExceptionalCallWithData(fc, useExprMemory{
				Loc: nil,
				DestType: lt,
				Model: "__cmplx_temp",
				Type: useExprAssignment,
				OpID: token::ASSIGN,
				OpKind: "=",
			})
			self.oc.write("\n")
			self.oc.indent()
		}

		self.assignLeft(l)
		self.oc.write(" = ")
		match opID {
		| token::ASSIGN:
			self.oc.ec.possibleRefExpr(r)
			ret
		| token::ADD_ASSIGN:
			if kind == types::Cmplx128 {
				identCoder.funcIns(&self.oc.Buf, meta::Program.Runtime.Cmplx128Add)
			} else {
				identCoder.funcIns(&self.oc.Buf, meta::Program.Runtime.Cmplx64Add)
			}
		| token::SUB_ASSIGN:
			if kind == types::Cmplx128 {
				identCoder.funcIns(&self.oc.Buf, meta::Program.Runtime.Cmplx128Sub)
			} else {
				identCoder.funcIns(&self.oc.Buf, meta::Program.Runtime.Cmplx64Sub)
			}
		| token::MUL_ASSIGN:
			if kind == types::Cmplx128 {
				identCoder.funcIns(&self.oc.Buf, meta::Program.Runtime.Cmplx128Mul)
			} else {
				identCoder.funcIns(&self.oc.Buf, meta::Program.Runtime.Cmplx64Mul)
			}
		| token::QUO_ASSIGN:
			if kind == types::Cmplx128 {
				identCoder.funcIns(&self.oc.Buf, meta::Program.Runtime.Cmplx128Div)
			} else {
				identCoder.funcIns(&self.oc.Buf, meta::Program.Runtime.Cmplx64Div)
			}
		|:
			panic("unreachable")
		}
		self.oc.write("(")
		self.assignLeft(l)
		self.oc.write(", ")
		if fc == nil {
			self.oc.ec.possibleRefExpr(r)
		} else {
			self.oc.write("__cmplx_temp")
		}
		self.oc.write(")")
		if fc != nil {
			self.oc.write(";\n")
			self.oc.doneIndent()
			self.oc.indent()
			self.oc.write("}")
		}
	}

	fn assign(mut &self, mut a: &sema::Assign) {
		self.pureAssign(a.Op, a.Op.ID, a.Op.Kind, a.Left.Model, a.Left.Type, a.Right.Model, a.Right.Type)
	}

	// The loc needed only if operation is division.
	fn pureAssign(mut &self, mut loc: &token::Token, mut opID: int, mut opKind: str, mut l: compExpr, mut lt: &sema::Type, mut r: compExpr, mut rt: &sema::Type) {
		// optimize may optimize multi-assign statements
		// it uses common tokens of normalized statement
		// so it may be := assignment token, it is not a bug
		// handle it like the equal operator
		if opID == token::DEFINE {
			opID = token::ASSIGN
			opKind = "="
		}

		lp := lt.Prim()
		if lp != nil && types::IsCmplx(lp.Kind) {
			self.cmplxAssign(opID, opKind, l, lt, r, rt, lp.Kind)
			ret
		}

		mut fc := isExceptionalResult(r)
		if fc != nil {
			self.oc.ec.handleExceptionalCallWithData(fc, useExprMemory{
				Loc: loc,
				DestType: lt,
				Model: l,
				Type: useExprAssignment,
				OpID: opID,
				OpKind: opKind,
			})
			ret
		}

		match opID {
		| token::QUO_ASSIGN | token::REM_ASSIGN:
			if env::Safety {
				self.divByZeroAssign(loc, opID, l, lt, r, rt)
				ret
			}
		| token::SHL_ASSIGN:
			self.shl(l, lt, r, rt)
			ret
		| token::SHR_ASSIGN:
			self.shr(l, lt, r, rt)
			ret
		}

		self.assignLeft(l)

		if rt.IsNil() || rt.Equal(lt) {
			self.oc.write(opKind)
			self.oc.ec.possibleRefExpr(r)
		} else {
			match {
			| obj::IsAny(lt):
				// Casted from any or type-enum, do nothing.
				// Make sure type is not strict type alias, because we have to cast it.
				if rt.SoftStruct() == nil && obj::IsAny(rt) {
					self.oc.write(opKind)
					self.oc.ec.possibleRefExpr(r)
					ret
				}
				self.oc.write(opKind)
				self.oc.write(typeAny + "(")
				self.oc.ec.possibleRefExpr(r)
				self.oc.write(", &" + anyTypeIdent)
				self.oc.write(conv::Itoa(self.oc.pushAnyType(rt)))
				self.oc.write(")")
			|:
				// It should be trait.
				if rt.Trait() != nil { // Different traits, cast.
					self.oc.write(opKind)
					mut t1 := lt.Trait()
					mut t2 := rt.Trait()
					self.oc.ec.possibleRefExpr(unsafe { *(*sema::Expr)(&r) })
					self.oc.write(".map(")
					self.oc.pushAndWriteMaskMapper(t1, t2)
					self.oc.write(")")
					break
				}
				t := lt.Trait()
				if t == nil { // No cast needed.
					self.oc.write(opKind)
					self.oc.ec.possibleRefExpr(r)
					break
				}
				self.oc.write(opKind)
				self.oc.write(typeTrait + "(")
				self.oc.ec.possibleRefExpr(r)
				self.oc.write(", (__jule_TypeMeta*)&")
				identCoder.traitDecl(&self.oc.Buf, t)
				self.oc.write("_mptr_data")
				self.oc.write(conv::Itoa(obj::FindTraitTypeOffset(t, rt)))
				self.oc.write(")")
			}
		}
		self.oc.write(";")
	}

	fn mapLookupAssign(mut &self, mut a: &sema::MultiAssign) {
		// map lookup right expression always should be indexing
		mut iem := a.Right.(&sema::IndexingExpr)
		mut _map := iem.Expr.Type.Map()

		mut ins := obj::FindStructGenericInstance(meta::Program.Runtime.Map, _map.Key, _map.Value)
		const Static = false
		mut f := ins.FindMethod("lookup", Static).Instances[0]

		identCoder.funcIns(&self.oc.Buf, f)
		self.oc.write("(")
		self.assignLeft(iem.Expr.Model)
		self.oc.write(".alloc, ")
		self.oc.ec.possibleRefExpr(iem.Index.Model)
		self.oc.write(", ")
		if a.Left[0] != nil {
			self.oc.write("&(")
			self.oc.ec.possibleRefExpr(a.Left[0].Model)
			self.oc.write("), ")
		} else {
			self.oc.write("nullptr, ")
		}
		if a.Left[1] != nil {
			self.oc.write("&(")
			self.oc.ec.possibleRefExpr(a.Left[1].Model)
			self.oc.write(")")
		} else {
			self.oc.write("nullptr")
		}
		self.oc.write(")")
	}

	fn multiAssignTuple(mut &self, mut a: &sema::MultiAssign) {
		self.oc.write("{\n")
		self.oc.addIndent()

		// tuple expressions may have reference for receiver memory
		// since receivers implemented as pointers they should take the pointer
		// to the actual expression of tuple
		// therefore do not generate temporary variable for references
		// they should take pointer from the tuple data

		mut tup := a.Right.(&sema::TupleExpr)

	Values:
		for (i, mut r) in tup.Values {
			self.oc.indent()
			mut l := a.Left[i]
			if l != nil {
				mut v, _ := l.Model.(&sema::Var)
				if v != nil && v.Reference {
					// left expression is a reference variable
					// lookup declared variables in this assignment
					// so we can detetermine reference variable is declared or assigned
					for _, dv in a.Decls {
						if v == dv {
							// variable is declaring now
							// takes pointer from the lvalue tuple data
							identCoder.var(&self.oc.Buf, v)
							self.oc.write(" = ")
							self.oc.ec.possibleRefExpr(r.Model)
							self.oc.write(";\n")
							a.Left[i] = nil // Ignore handling for following statements.
							continue Values
						}
					}
					// variable is not exist in declared variables
					// it can take temporary variable strategy
					// it just takes assignment to the pointing data
					// not takes pointer of the lvalue data
				}
				self.oc.tc.kind(&self.oc.Buf, l.Type)
				self.oc.write(" ")
				identCoder.toOut(&self.oc.Buf, assignArgName, uintptr(i))
				self.oc.write(" = ")
			}
			self.oc.ec.possibleRefExpr(r.Model)
			self.oc.write(";\n")
		}

		for (i, mut l) in a.Left {
			if l == nil {
				continue
			}
			self.oc.indent()
			self.assignLeft(l.Model)
			self.oc.write(" = ")
			identCoder.toOut(&self.oc.Buf, assignArgName, uintptr(i))
			self.oc.write(";\n")
		}

		self.oc.doneIndent()
		self.oc.indent()
		self.oc.write("}")
	}

	fn multiAssignFunc(mut &self, mut a: &sema::MultiAssign) {
		self.oc.write("{\n")
		self.oc.addIndent()
		self.oc.indent()

		mut fc := a.Right.(&sema::FuncCallExpr)
		self.oc.tc.rc.codeMut1(&self.oc.Buf, fc.Func.Result)
		if fc.Func.Decl != nil && fc.Func.Decl.Exceptional {
			let mut dest = useExprMemory{
				Loc: nil,
				DestType: nil, // Should not be required in this case.
				Model: assignResultName,
				Type: useExprPlain,
				OpID: token::ASSIGN,
				OpKind: "=",
			}
			self.oc.write(" " + assignResultName + ";\n")
			self.oc.indent()
			self.oc.ec.handleExceptionalCallWithData(fc, dest)
			self.oc.write("\n")
		} else {
			self.oc.write(" " + assignResultName + " = ")
			self.oc.ec.possibleRefExpr(a.Right)
			self.oc.write(";\n")
		}

		mut tup := fc.Func.Result.Tuple()
		mut r := &sema::Var{
			Extern: true, // to use identifier directly
		}
		for (i, mut l) in a.Left {
			if l == nil {
				continue
			}
			r.Name = assignResultName + "." + resultArgName + conv::Itoa(i)
			self.oc.indent()
			self.pureAssign(nil, token::ASSIGN, "=", l.Model, l.Type, r, tup.Types[i])
			self.oc.write("\n")
		}

		self.oc.doneIndent()
		self.oc.indent()
		self.oc.write("}")
	}

	// Handles channel receive expression assignments like; data, ok := <-c
	fn chanRecvAssign(mut &self, mut a: &sema::MultiAssign) {
		if a.Left[0] == nil && a.Left[1] == nil {
			// Expression is like: _, _ = <-c
			// Handle as plain expression.
			self.oc.ec.chanRecv(a.Right.(&sema::ChanRecv), nil)
			ret
		}
		if a.Left[0] != nil {
			// Received data assigned to this.
			self.oc.ec.possibleRefExpr(a.Left[0].Model)
			self.oc.write(" = ")
		}
		let mut ok: fn() = nil
		if a.Left[1] != nil {
			// The |ok| parameter found.
			// Pass the memory of the lvalue to the receiver function.
			ok = fn|| {
				self.oc.write("&(")
				self.oc.ec.possibleRefExpr(a.Left[1].Model)
				self.oc.write(")")
			}
		}
		self.oc.ec.chanRecv(a.Right.(&sema::ChanRecv), ok)
	}

	fn typeAssertionAssign(mut &self, mut a: &sema::MultiAssign) {
		mut ce := a.Right.(&sema::TypeAssertionExpr)
		mut f := obj::FindFuncGenericInstance(meta::Program.Runtime.DynAssertAssign, ce.Expr.Type, ce.Type)
		identCoder.funcIns(&self.oc.Buf, f)
		self.oc.write("(")
		self.assignLeft(ce.Expr.Model)
		self.oc.write(", ")
		if a.Left[0] != nil {
			self.oc.write("&(")
			self.oc.ec.possibleRefExpr(a.Left[0].Model)
			self.oc.write("), ")
		} else {
			self.oc.write("nullptr, ")
		}
		if a.Left[1] != nil {
			self.oc.write("&(")
			self.oc.ec.possibleRefExpr(a.Left[1].Model)
			self.oc.write(")")
		} else {
			self.oc.write("nullptr")
		}
		self.oc.write(")")
	}

	fn typeAssertionAssignUnsafe(mut &self, mut a: &sema::MultiAssign, mut uc: &opt::UnsafeTypeAssertionExpr) {
		if a.Left[0] != nil {
			self.oc.ec.possibleRefExpr(a.Left[0].Model)
			self.oc.write(" = ")
		}
		self.oc.ec.unsafeTypeAssertion(uc)
		if a.Left[1] != nil {
			self.oc.write(";\n")
			self.oc.indent()
			self.oc.ec.possibleRefExpr(a.Left[1].Model)
			self.oc.write(" = true")
		}
	}

	fn multiAssign(mut &self, mut a: &sema::MultiAssign) {
		// Write declarations without no initialization.
		// It will initialize with assignments.
		for (_, mut d) in a.Decls {
			self.oc.varInitExpr(d, nil)
			self.oc.write("\n")
			self.oc.indent()
		}

		let mut r: compExpr = a.Right
		match type r {
		| &sema::IndexingExpr:
			self.mapLookupAssign(a)
			ret
		| &sema::TypeAssertionExpr:
			self.typeAssertionAssign(a)
			ret
		| &opt::UnsafeTypeAssertionExpr:
			// We avoiding misanalysis for assertion casting expressions here.
			// Since we know the casting result, assign directly with no analysis.
			mut uc := r.(&opt::UnsafeTypeAssertionExpr)
			self.typeAssertionAssignUnsafe(a, uc)
			ret
		| &sema::ChanRecv:
			self.chanRecvAssign(a)
			ret
		| &sema::TupleExpr:
			self.multiAssignTuple(a)
		| &sema::FuncCallExpr:
			self.multiAssignFunc(a)
		|:
			panic("cxx: this panic call should be unreachable")
		}
	}

	fn case(mut &self, mut m: &sema::Match, mut l: sema::OperandExpr, mut c: &sema::Case) {
		if len(c.Exprs) != 0 && !m.Comptime {
			if len(m.Cases) > 0 && m.Cases[0] == c {
				self.oc.write("if (")
			} else {
				self.oc.write("else if (")
			}
			for (i, mut expr) in c.Exprs {
				match {
				| !m.TypeMatch:
					mut r := sema::OperandExpr{
						Model: expr.Model,
						Type: expr.Type,
					}
					self.oc.ec._unsafeBinary(&self.oc.Buf, l, r, token::EQL, "==")
				|:
					self.oc.write(matchExpr)
					mut tk := expr.Type
					if m.Expr.Type.Trait() != nil { // Trait type.
						t := m.Expr.Type.Trait()
						self.oc.write(".type == (__jule_TypeMeta*)&")
						identCoder.traitDecl(&self.oc.Buf, t)
						self.oc.write("_mptr_data")
						self.oc.write(conv::Itoa(obj::FindTraitTypeOffset(m.Expr.Type.Trait(), expr.Type)))
					} else { // Any type.
						j := self.oc.pushAnyType(tk)
						self.oc.write(".type == &" + anyTypeIdent)
						self.oc.write(conv::Itoa(j))
					}
				}

				if len(c.Exprs)-i > 1 {
					self.oc.write(" || ")
				}
			}
			self.oc.write(") ")
		} else if m.Default == c && len(m.Cases) != 0 {
			self.oc.indent()
			self.oc.write("else ")
		}

		self.oc.addIndent()

		self.oc.write("{\n")
		self.oc.indent()
		identCoder.caseBegin(&self.oc.Buf, uintptr(c), self.registerAddrmap(uintptr(c)))
		self.oc.write(":;\n")
		if len(c.Scope.Stmts) > 0 {
			self.oc.indent()
			self.scope(c.Scope)
			self.oc.write("\n")
		}

		self.oc.doneIndent()

		self.oc.indent()
		self.oc.write("}")
	}

	fn matchStmt(mut &self, mut m: &sema::Match) {
		if len(m.Cases) == 0 && m.Default == nil {
			ret
		}
		if m.Comptime && (m.Default == nil || len(m.Default.Scope.Stmts) == 0) {
			ret
		}
		self.oc.write("{\n")
		self.oc.addIndent()
		self.oc.indent()

		addrmap := self.registerAddrmap(uintptr(m))

		mut l := sema::OperandExpr{}

		// Constant expressions generated as literals in conditions.
		if !m.Comptime {
			l.Type = m.Expr.Type
			if m.Expr.IsConst() {
				matchExprS := writeAndReadFromBuf(&self.oc.Buf,
					fn|| self.oc.ec.possibleRefExpr(m.Expr.Model))
				mut matchExpr := compExpr(matchExprS)
				l.Model = unsafe { *(*sema::Expr)(&matchExpr) }
			} else {
				if opt::Copy && isCopyOptimizable(m.Expr, false) {
					self.oc.write("auto &_match_expr{ ")
				} else {
					self.oc.write("auto _match_expr{ ")
				}
				mut matchExpr := compExpr(matchExpr)
				l.Model = unsafe { *(*sema::Expr)(&matchExpr) }
				self.oc.ec.possibleRefExpr(m.Expr.Model)
				self.oc.write(" };\n")
				self.oc.indent()
			}
		}

		if len(m.Cases) > 0 {
			for (_, mut c) in m.Cases {
				if c == nil {
					continue
				}
				self.oc.write("\n")
				self.oc.indent()
				self.case(m, l, c)
			}
		}

		if m.Default != nil {
			self.oc.write("\n")
			self.case(m, l, m.Default)
		}

		self.oc.write("\n")
		self.oc.indent()
		identCoder.matchEnd(&self.oc.Buf, uintptr(m), addrmap)
		self.oc.write(":;")
		self.oc.write("\n")

		self.oc.doneIndent()

		self.oc.indent()
		self.oc.write("}")
	}

	fn selectStmt(mut &self, mut slct: &sema::Select) {
		if len(slct.Cases) == 0 {
			// Empty select.
			if slct.Default == nil {
				self.oc.write("__jule_AsyncAwait ")
				identCoder.funcIns(&self.oc.Buf, meta::Program.Runtime.Emptyselect)
				self.oc.write("();")
			} else {
				// Just the default case.
				self.scope(slct.Default.Scope)
			}
			ret
		}
		block := slct.Default == nil

		addrmap := self.registerAddrmap(uintptr(slct))

		// Single case. No need for complex handling.
		if block && len(slct.Cases) == 1 {
			self.oc.write("{\n")
			self.oc.addIndent()
			self.oc.indent()
			mut case := slct.Cases[0]
			match type case.Stmt {
			| &sema::Value:
				mut v := case.Stmt.(&sema::Value)
				self.oc.ec.possibleRefExpr(v.Model)
				self.oc.write(";")
			| &sema::Var:
				mut v := case.Stmt.(&sema::Var)
				self.oc.varInitExpr(v, fn|| self.oc.ec.possibleRefExpr(v.ValueSym.Value.Model))
			| &sema::Assign:
				mut assign := case.Stmt.(&sema::Assign)
				self.assign(assign)
			|:
				panic("unreachable")
			}
			if len(case.Scope.Stmts) > 0 {
				self.oc.write("\n")
				self.oc.indent()
				self.scope(case.Scope)
			}
			self.oc.doneIndent()
			self.oc.write("\n")
			self.oc.indent()
			identCoder.matchEnd(&self.oc.Buf, uintptr(slct), addrmap)
			self.oc.write(":;")
			self.oc.write("\n")
			self.oc.indent()
			self.oc.write("}")
			ret
		}

		mut scase := ""
		mut scaseCh := ""
		mut scaseData := ""
		mut scaseTryRecv := ""
		mut scaseTryRecvImmediate := ""
		mut scaseTrySend := ""
		mut scaseTrySendImmediate := ""
		{
			mut scaseIns := meta::Program.Runtime.Scase
			let mut scaseBuf: strings::Builder
			self.oc.tc.structureIns(&scaseBuf, scaseIns)
			scase = scaseBuf.Str()
			scaseBuf.Clear()
			identCoder.field(&scaseBuf, scaseIns.FindField("ch").Decl)
			scaseCh = scaseBuf.Str()
			scaseBuf.Clear()
			identCoder.field(&scaseBuf, scaseIns.FindField("data").Decl)
			scaseData = scaseBuf.Str()
			scaseBuf.Clear()
			identCoder.field(&scaseBuf, scaseIns.FindField("tryRecv").Decl)
			scaseTryRecv = scaseBuf.Str()
			scaseBuf.Clear()
			identCoder.field(&scaseBuf, scaseIns.FindField("tryRecvImmediate").Decl)
			scaseTryRecvImmediate = scaseBuf.Str()
			scaseBuf.Clear()
			identCoder.field(&scaseBuf, scaseIns.FindField("trySend").Decl)
			scaseTrySend = scaseBuf.Str()
			scaseBuf.Clear()
			identCoder.field(&scaseBuf, scaseIns.FindField("trySendImmediate").Decl)
			scaseTrySendImmediate = scaseBuf.Str()
		}

		let mut chanArr: strings::Builder
		let mut recvArr: strings::Builder
		let mut sendArr: strings::Builder
		let mut nchan: int
		let mut nrecv: int
		let mut nsend: int

		self.oc.write("{\n")
		self.oc.addIndent()

		self.oc.indent()
		self.oc.write(typeInt)
		self.oc.write(" __selectIndex;\n")

		registerChan := fn(mut &buf: *strings::Builder, mut ch: &sema::Chan, data: str, n: int) {
			buf.WriteStr(scase)!
			buf.WriteStr("{.")!
			buf.WriteStr(scaseCh)!
			buf.WriteStr("=&__chanArr[")!
			buf.WriteStr(conv::Itoa(n))!
			buf.WriteStr("], .")!
			if data != "" {
				buf.WriteStr(scaseData)!
				buf.WriteStr("=(")!
				buf.WriteStr(typeUintptr)!
				buf.WriteStr(")")!
				if data[0] == '*' { // Data is pointer already.
					buf.WriteStr(data[1:])!
				} else {
					buf.WriteByte('&')!
					buf.WriteStr(data)!
				}
				buf.WriteStr(", .")!
			}
			mut ins := obj::FindStructGenericInstance(meta::Program.Runtime.Pchan, ch.Value)
			const Extern = false
			mut tryRecv := ins.FindMethod("tryRecv", Extern).Instances[0]
			mut tryRecvImmediate := ins.FindMethod("tryRecvImmediate", Extern).Instances[0]
			mut trySend := ins.FindMethod("trySend", Extern).Instances[0]
			mut trySendImmediate := ins.FindMethod("trySendImmediate", Extern).Instances[0]

			buf.WriteStr(scaseTryRecv)!
			buf.WriteStr("=(")!
			buf.WriteStr(typeUintptr)!
			buf.WriteByte(')')!
			identCoder.funcIns(buf, tryRecv)
			buf.WriteStr(", .")!
			buf.WriteStr(scaseTryRecvImmediate)!
			buf.WriteStr("=(")!
			buf.WriteStr(typeUintptr)!
			buf.WriteByte(')')!
			identCoder.funcIns(buf, tryRecvImmediate)
			buf.WriteStr(", .")!
			buf.WriteStr(scaseTrySend)!
			buf.WriteStr("=(")!
			buf.WriteStr(typeUintptr)!
			buf.WriteByte(')')!
			identCoder.funcIns(buf, trySend)
			buf.WriteStr(", .")!
			buf.WriteStr(scaseTrySendImmediate)!
			buf.WriteStr("=(")!
			buf.WriteStr(typeUintptr)!
			buf.WriteByte(')')!
			identCoder.funcIns(buf, trySendImmediate)

			buf.WriteByte('}')!
		}

		// We have to evaluate all expressions of the cases.
		for (_, mut case) in slct.Cases {
			caseHex := conv::FormatUint(u64(uintptr(case)), 16)
			let mut data: str
			let mut value: sema::Expr
			match type case.Stmt {
			| &sema::Value:
				value = case.Stmt.(&sema::Value).Model
				match type value {
				| &sema::ChanSend:
					mut cs := value.(&sema::ChanSend)

					data = "__var_" + caseHex

					// Evaluate the data to be sent.
					self.oc.indent()
					self.oc.tc.kind(&self.oc.Buf, cs.Data.Type)
					self.oc.write(" ")
					self.oc.write(data)
					self.oc.write("=")
					self.oc.ec.possibleRefExpr(cs.Data.Model)
					self.oc.write(";\n")
				| &sema::ChanRecv:
					// no-op
				|:
					panic("unreachable")
				}
			| &sema::Var:
				mut v := case.Stmt.(&sema::Var)

				// Declare the variable to receive the data.
				self.oc.indent()
				self.oc.varInitExpr(v, nil)
				self.oc.write("\n")

				let mut varBuf: strings::Builder
				identCoder.var(&varBuf, v)
				data = varBuf.Str()
				value = v.ValueSym.Value.Model
			| &sema::Assign:
				mut assign := case.Stmt.(&sema::Assign)

				data = "*__var_" + caseHex // * prefix is a placeholder for memory address data.
				value = assign.Right.Model

				// Evaluate the memory address to receive the data.
				self.oc.indent()
				self.oc.tc.kind(&self.oc.Buf, assign.Left.Type)
				self.oc.write(" ")
				self.oc.write(data)
				self.oc.write("=&")
				self.oc.ec.possibleRefExpr(assign.Left.Model)
				self.oc.write(";\n")
			|:
				panic("unreachable")
			}

			let mut chanValue: &sema::Value
			match type value {
			| &sema::ChanSend:
				if nsend > 0 {
					sendArr.WriteStr(", ")!
				}
				nsend++

				mut cs := value.(&sema::ChanSend)
				chanValue = cs.Chan

				registerChan(&sendArr, chanValue.Type.Chan(), data, nchan)
			| &sema::ChanRecv:
				if nrecv > 0 {
					recvArr.WriteStr(", ")!
				}
				nrecv++

				mut cr := value.(&sema::ChanRecv)
				chanValue = cr.Expr

				registerChan(&recvArr, chanValue.Type.Chan(), data, nchan)
			|:
				panic("unreachable")
			}

			if nchan > 0 {
				chanArr.WriteStr(", ")!
			}
			nchan++
			n := self.oc.Buf.Len()
			self.oc.ec.possibleRefExpr(chanValue.Model)
			mut buf := unsafe { self.oc.Buf.Buf() }
			chanArr.Write(buf[n:])!
			unsafe { self.oc.Buf.SetBuf(buf[:n]) }
			chanArr.WriteStr(".as<")!
			chanArr.WriteStr(typeUintptr)!
			chanArr.WriteStr(">()")!
		}

		self.oc.indent()
		self.oc.write("{\n")
		self.oc.addIndent()

		self.oc.indent()
		self.oc.tc.asSptr2(&self.oc.Buf, typeUintptr)
		self.oc.write(" __chanArr[] = {")
		self.oc.write(chanArr.Str())
		self.oc.write("};\n")

		self.oc.indent()
		self.oc.write(scase)
		self.oc.write(" __caseArr[] = {")
		self.oc.write(recvArr.Str())
		if nsend > 0 {
			if nrecv > 0 {
				self.oc.write(", ")
			}
			self.oc.write(sendArr.Str())
		}
		self.oc.write("};\n")

		self.oc.indent()
		self.oc.write("__selectIndex = __jule_AsyncAwait ")
		identCoder.funcIns(&self.oc.Buf, meta::Program.Runtime.Runselect)
		self.oc.write("(__chanArr, ")
		self.oc.write(conv::Itoa(nchan))
		self.oc.write(", __caseArr, ")
		self.oc.write(conv::Itoa(nrecv))
		self.oc.write(", ")
		self.oc.write(conv::Itoa(nsend))
		self.oc.write(", ")
		self.oc.ec.boolean(block)
		self.oc.write(");\n")

		self.oc.doneIndent()
		self.oc.indent()
		self.oc.write("}\n")

		self.oc.indent()
		self.oc.write("switch (__selectIndex) {\n")
		for (i, mut case) in slct.Cases {
			self.oc.indent()
			self.oc.write("case ")
			self.oc.write(conv::Itoa(i))
			self.oc.write(":\n")
			self.oc.addIndent()
			self.oc.indent()
			self.scope(case.Scope)
			self.oc.write("\n")
			self.oc.indent()
			self.oc.write("break;\n")
			self.oc.doneIndent()
		}
		if slct.Default != nil {
			self.oc.indent()
			self.oc.write("default:\n")
			self.oc.addIndent()
			self.oc.indent()
			self.scope(slct.Default.Scope)
			self.oc.write("\n")
			self.oc.indent()
			self.oc.write("break;\n")
			self.oc.doneIndent()
		}
		self.oc.indent()
		self.oc.write("}\n")
		self.oc.indent()
		identCoder.matchEnd(&self.oc.Buf, uintptr(slct), addrmap)
		self.oc.write(":;")
		self.oc.write("\n")
		self.oc.doneIndent()
		self.oc.indent()
		self.oc.write("}")
	}

	fn fallStmt(mut &self, f: &sema::Fall) {
		mut case := unsafe { (&sema::Case)((*sema::Case)(f.DestCase)) }
		self.emitDefersByLevel(case.Scope.ChildIndex+1, false)
		self.oc.write("goto ")
		identCoder.caseBegin(&self.oc.Buf, f.DestCase, self.getAddrmap(f.DestCase))
	}

	fn breakStmt(mut &self, b: &sema::Break) {
		mut childIndex := -1
		match {
		| b.It != 0:
			childIndex = unsafe { (*(*&sema::Scope)(b.It)).ChildIndex }
			childIndex++
		| b.Match != 0:
			childIndex = unsafe { (*(*&sema::Scope)(b.Match)).ChildIndex }
			childIndex += 2
		| b.Select != 0:
			childIndex = unsafe { (*(*&sema::Scope)(b.Select)).ChildIndex }
			childIndex += 2
		|:
			panic("unreachable")
		}
		self.emitDefersByLevel(childIndex, false)
		self.oc.write("goto ")
		match {
		| b.It != 0:
			identCoder.iterEnd(&self.oc.Buf, b.It, self.getAddrmap(b.It))
		| b.Match != 0:
			identCoder.matchEnd(&self.oc.Buf, b.Match, self.getAddrmap(b.Match))
		| b.Select != 0:
			identCoder.matchEnd(&self.oc.Buf, b.Select, self.getAddrmap(b.Select))
		|:
			panic("unreachable")
		}
	}

	fn setResult(mut &self, mut r: &sema::Ret) {
		mut fc := isExceptionalResult(r.Expr)
		if fc != nil {
			// If result types are not equal, must be handled like an assign.
			// See the documentation of the &FuncCallExpr case below.
			if !r.Func.Result.Equal(fc.Func.Result) {
				goto assignFC
			}
			let mut dest = useExprMemory{
				Loc: nil,
				DestType: nil, // Should not be required in this case.
				Model: resultName,
				Type: useExprPlain,
				OpID: token::ASSIGN,
				OpKind: "=",
			}
			self.oc.ec.handleExceptionalCallWithData(fc, dest)
			self.oc.write("\n")
			self.oc.indent()
			ret
		}

		if len(r.Func.Decl.Result.Names) == 1 {
			self.oc.write(resultName + " = ")
			self.oc.ec.possibleRefExpr(r.Expr)
			self.oc.write(";\n")
			self.oc.indent()
			ret
		}
		match type r.Expr {
		| &sema::TupleExpr:
			mut values := r.Expr.(&sema::TupleExpr).Values
			for (i, mut v) in values {
				self.oc.write(resultName + "." + resultArgName)
				self.oc.write(conv::Itoa(i))
				self.oc.write(" = ")
				self.oc.ec.possibleRefExpr(v.Model)
				self.oc.write(";\n")
				self.oc.indent()
			}
			ret
		| &sema::FuncCallExpr:
			// If function call could not returned by isExceptionalResult,
			// the use the pure function call.
			if fc == nil {
				fc = r.Expr.(&sema::FuncCallExpr)
			}
			// If result types are equal, assign directly.
			// Otherwise, we probably need casting due to dynamic types.
			if r.Func.Result.Equal(fc.Func.Result) {
				self.oc.write(resultName + " = std::move(")
				self.oc.ec.model(r.Expr)
				self.oc.write(");\n")
				self.oc.indent()
				ret
			}
			goto assignFC
		|:
			panic("cxx: implementation mistake, this panic call should be unreachable")
		}
	assignFC:
		// Handle like an assignment.
		// The assignment handler will do the task.
		mut tup := r.Func.Result.Tuple()
		if tup == nil {
			// Single type, handle like an single assignment.
			let mut rv = &sema::Var{
				Extern: true, // to use identifier directly
				Name: resultName,
			}
			mut dest := useExprMemory{
				Loc: nil,
				DestType: r.Func.Result,
				Model: rv,
				Type: useExprPlain,
				OpID: token::ASSIGN,
				OpKind: "=",
			}
			self.oc.ec.handleExceptionalCallWithData(fc, dest)
		} else {
			mut a := new(sema::MultiAssign)
			a.Decls = nil // not needed
			a.Op = nil    // not needed
			a.Right = r.Expr
			a.Left = make([]&sema::Value, len(tup.Types))
			for i in a.Left {
				mut ident := resultName + "." + resultArgName
				ident += conv::Itoa(i)
				a.Left[i] = &sema::Value{
					Type: tup.Types[i],
					Model: &sema::Var{
						Extern: true, // to use identifier directly
						Name: ident,
					},
				}
			}
			self.multiAssign(a)
		}
		self.oc.write("\n")
		self.oc.indent()
	}

	fn retStmt(mut &self, mut r: &sema::Ret) {
		hasDefer := r.Func.Decl != nil && r.Func.Decl.HasDefer
		mut fc := isExceptionalResult(r.Expr) // Exceptional functions should be handled with setResult.
		if r.Func.Decl.IsVoid() {
			if hasDefer {
				self.emitDefers(0, false)
				self.oc.write("\n")
				self.oc.indent()
			}
			if r.Func.Decl.Exceptional {
				self.oc.write(returnKw(r.Func))
				self.oc.write(" __jule_VoidExceptional{};")
				ret
			}
			self.oc.write(returnKw(r.Func))
			self.oc.write(";")
			ret
		} else if len(r.Func.Decl.Result.Names) == 0 && fc == nil {
			if r.Func.Decl.Exceptional {
				// Use scope to prevent "goto" errors about declarations.
				self.oc.write("{\n")
				self.oc.addIndent()
				self.oc.indent()
				self.oc.write("__jule_Exceptional<")
				self.oc.tc.kind(&self.oc.Buf, r.Func.Result)
				self.oc.write("> result;\n")
				self.oc.indent()
				self.oc.write("result.result = ")
				self.oc.ec.possibleRefExpr(r.Expr)
				self.oc.write(";\n")
				if hasDefer {
					self.emitDefers(0, false)
					self.oc.write("\n")
					self.oc.indent()
				} else {
					self.oc.indent()
				}
				self.oc.write(returnKw(r.Func))
				self.oc.write(" result;\n")
				self.oc.doneIndent()
				self.oc.indent()
				self.oc.write("}")
			} else {
				self.oc.write("{\n")
				self.oc.addIndent()
				self.oc.indent()
				if hasDefer {
					self.oc.tc.kind(&self.oc.Buf, r.Func.Result)
					self.oc.write(" __result = ")
				} else {
					self.oc.write(returnKw(r.Func))
					self.oc.write(" ")
				}
				self.oc.ec.possibleRefExpr(r.Expr)
				if hasDefer {
					self.oc.write(";\n")
					self.emitDefers(0, false)
					self.oc.write("\n")
					self.oc.indent()
					self.oc.write(returnKw(r.Func))
					self.oc.write(" __result;\n")
				} else {
					self.oc.write(";\n")
				}
				self.oc.doneIndent()
				self.oc.indent()
				self.oc.write("}")
			}
			ret
		}

		// If function have not explicit result variables, push to stack temporarily.
		// We need to allocate just one variable, because this is the only possible case.
		// Probably needed for implicit casting.
		needResultVar := len(r.Func.Decl.Result.Names) != 1 && r.Func.Result.Tuple() == nil
		if needResultVar {
			self.oc.write("{\n")
			self.oc.addIndent()
			self.oc.indent()

			self.oc.tc.kind(&self.oc.Buf, r.Func.Result)
			self.oc.write(" " + resultName)
			if shouldInitialized(r.Func.Result) {
				self.oc.write(" = ")
				self.oc.ec.initExpr(r.Func.Result)
			}
			self.oc.write(";\n")
			self.oc.indent()
		}

		if r.Expr != nil {
			self.setResult(r)
		}

		// Emit deferred scopes, if any.
		if hasDefer {
			self.emitDefers(0, false)
			self.oc.write("\n")
			self.oc.indent()
		}
		if r.Func.Decl.Exceptional {
			self.oc.write(returnKw(r.Func))
			self.oc.write(" __jule_Exceptional<")
			self.oc.tc.rc.codeMut1(&self.oc.Buf, r.Func.Result)
			self.oc.write(">{.result=" + resultName + "};")
		} else {
			self.oc.write(returnKw(r.Func))
			self.oc.write(" " + resultName + ";")
		}

		// Close the result variable scope.
		if needResultVar {
			self.oc.write("\n")
			self.oc.doneIndent()
			self.oc.indent()
			self.oc.write("}")
		}
	}

	fn var(mut &self, mut v: &sema::Var) {
		if !v.Constant {
			self.oc.var(v)
		}
	}

	fn mutSlicing(mut &self, mut m: &opt::MutSlicingExpr) {
		self.oc.write("(")
		self.oc.ec.possibleRefExpr(m.Expr)
		self.oc.write(").safe_mut_slice(\"")
		self.oc.locInfo(m.Token)
		self.oc.write("\", ")
		self.oc.ec.possibleRefExpr(m.Left)
		if m.Right != nil {
			self.oc.write(", ")
			self.oc.ec.possibleRefExpr(m.Right)
		}
		if m.Cap != nil {
			self.oc.write(", ")
			self.oc.ec.possibleRefExpr(m.Cap)
		}
		self.oc.write(");")
	}

	fn swap(mut &self, mut m: &opt::SwapExpr) {
		self.oc.write("std::swap(")
		self.oc.ec.possibleRefExpr(m.Left.Model)
		self.oc.write(", ")
		self.oc.ec.possibleRefExpr(m.Right.Model)
		self.oc.write(")")
	}

	fn exceptionalForwarding(mut &self, mut m: &opt::ExceptionalForwardingExpr) {
		hasDefer := m.Func.Decl != nil && m.Func.Decl.HasDefer
		if !hasDefer {
			self.oc.write(returnKw(m.Func))
			self.oc.write(" ")
			self.oc.ec.pureFuncCall(m.Expr)
			ret
		}
		if m.Func.Decl.IsVoid() {
			self.oc.write("__jule_VoidExceptional")
		} else {
			self.oc.write("__jule_Exceptional<")
			self.oc.tc.rc.codeMut1(&self.oc.Buf, m.Func.Result)
			self.oc.write(">")
		}
		self.oc.write(" __result = ")
		self.oc.ec.pureFuncCall(m.Expr)
		self.oc.write(";\n")
		self.emitDefers(0, false)
		self.oc.indent()
		self.oc.write(returnKw(m.Func))
		self.oc.write(" __result;")
	}

	// Generates C++ code of statement.
	fn st(mut &self, mut st: compStmt) {
		if st == nil {
			ret
		}
		match type st {
		| &sema::Scope:
			self.scope(st.(&sema::Scope))
		| &sema::Var:
			self.var(st.(&sema::Var))
		| &sema::Value:
			mut v := st.(&sema::Value)
			self.oc.ec.model(v.Model)
		| &sema::Conditional:
			self.conditional(st.(&sema::Conditional))
		| &sema::InfIter:
			self.infIter(st.(&sema::InfIter))
		| &sema::WhileIter:
			self.whileIter(st.(&sema::WhileIter))
		| &sema::RangeIter:
			self.rangeIter(st.(&sema::RangeIter))
		| &sema::Continue:
			self.continueStmt(st.(&sema::Continue))
		| &sema::Label:
			self.label(st.(&sema::Label))
		| &sema::Goto:
			self.gotoStmt(st.(&sema::Goto))
		| &sema::Postfix:
			self.postfix(st.(&sema::Postfix))
		| &sema::Assign:
			self.assign(st.(&sema::Assign))
		| &sema::MultiAssign:
			self.multiAssign(st.(&sema::MultiAssign))
		| &sema::Match:
			self.matchStmt(st.(&sema::Match))
		| &sema::Select:
			self.selectStmt(st.(&sema::Select))
		| &sema::Fall:
			self.fallStmt(st.(&sema::Fall))
		| &sema::Break:
			self.breakStmt(st.(&sema::Break))
		| &sema::Ret:
			self.retStmt(st.(&sema::Ret))
		| &opt::PushToSliceExpr:
			self.oc.ec.pushToSlice(st.(&opt::PushToSliceExpr))
		| &opt::MutSlicingExpr:
			self.mutSlicing(st.(&opt::MutSlicingExpr))
		| &opt::SwapExpr:
			self.swap(st.(&opt::SwapExpr))
		| &opt::ExceptionalForwardingExpr:
			self.exceptionalForwarding(st.(&opt::ExceptionalForwardingExpr))
		| &opt::StrRuneIter:
			mut sit := st.(&opt::StrRuneIter)
			self.strRuneIter(*sit, false)
		| &sema::Use:
			// no-op
		}
	}

	fn scopeStmts(mut &self, mut s: &sema::Scope) {
		for (_, mut st) in s.Stmts {
			self.oc.indent()
			self.st(st)
			self.oc.write(";\n")
		}
	}

	// Emits the deferred scope ds.
	fn emitDefer(mut &self, mut ds: &sema::Scope) {
		self.__scope(ds, false)
	}

	// Emits memorized deferred scopes.
	// The nds is the count of the deferred scopes before handling a new scope.
	// Emits new deferred scopes since nds.
	// If remove is true, removes the emitted deferred scopes.
	fn emitDefers(mut &self, nds: int, remove: bool) {
		mut diff := len(self.deferredScopes) - nds
		if diff <= 0 {
			ret
		}
		mut i := len(self.deferredScopes) - 1
		for diff > 0; diff, i = diff-1, i-1 {
			mut ds := self.deferredScopes[i]
			self.emitDefer(ds)
		}
		if remove {
			self.deferredScopes = self.deferredScopes[:nds]
		}
	}

	// Emits memorized deferred scopes.
	// The childIndex is the destination scope's index.
	// Emits deferred scopes to childIndex's scope, including it.
	// If remove is true, removes the emitted deferred scopes.
	//
	// To emit the deferred scopes within a particular scope,
	// the `ChildIndex+1` relation is generally required.
	// This is because deferred scopes that share the same `ChildIndex` may
	// otherwise be captured.
	//
	//	Scheme on pseudo AST
	//		
	//		 fn example() {              > ChildIndex=0
	//		     mut x := 0             
	//		     for {                   > ChildIndex=1
	//		         defer { x++ }       > ChildIndex=2
	//		         {                   > ChildIndex=2
	//		             defer { x++ }   > ChildIndex=3
	//		             break          
	//		         }                  
	//		     }                      
	//		 }                          
	//		
	//
	//		In the example above, if you directly use the `ChildIndex` value of
	//		that scope-i.e., `ChildIndex=2`-to emit the deferred scopes of the
	//		anonymous scope inside the iteration, this will successfully emit the
	//		deferred scope with `ChildIndex=3`. However, since the defer scope
	//		defined in the main body of the iteration also has `ChildIndex=2`,
	//		it will also tend to be emitted. Using `ChildIndex+1` here results in
	//		`ChildIndex=3` and guarantees that only the deferred scopes inside the
	//		anonymous scope are emitted.
	fn emitDefersByLevel(mut &self, childIndex: int, remove: bool) {
		mut i := len(self.deferredScopes) - 1
		for i >= 0; i-- {
			mut ds := self.deferredScopes[i]
			if childIndex <= ds.ChildIndex {
				self.emitDefer(ds)
			} else {
				break
			}
		}
		if remove {
			self.deferredScopes = self.deferredScopes[:i+1]
		}
	}

	// Generates C++ code of a scope.
	// But this is a pure generation routine.
	// If scope is a deferred scope, it will not memorize it.
	// Generates the code for the scope s, anyway.
	fn __scope(mut &self, mut s: &sema::Scope, stmt: bool) {
		nds := len(self.deferredScopes)

		if !stmt {
			self.oc.addIndent()
			self.oc.write("{\n")
		}
		self.scopeStmts(s)

		// If we have new deferred scopes, emit them.
		// Because they are placed in this scope.
		// But if the scope is an error handle scope, do not emit deferred scopes.
		// The error handler codegen is responsible for this.
		if s.Traits&sema::ST_ERROR_HANDLER == 0 {
			// An `nds`-based detection is used here.
			// If a ChildIndex-based detection were used,
			// an incorrect emit could occur.
			// This is because ChildIndex-based detection operates as `<=ChildIndex`.
			// As a result, deferred scopes located in outer scopes may capture
			// scopes that are actually in more inner levels.
			//
			// Scheme on pseudo AST
			//	
			//	 fn example() {              > ChildIndex=0
			//	     mut x := 0             
			//	     for {                   > ChildIndex=1
			//	         defer { x++ }       > ChildIndex=2
			//	         {                   > ChildIndex=2
			//	             defer { x++ }   > ChildIndex=3
			//	             break          
			//	         }                  
			//	     }                      
			//	 }                          
			//	
			//
			//		In the situation above, when the `break` statement exits the
			//		loop, both deferred scopes must be emitted.
			//		However, while emitting the deferred scope defined in the
			//		loop body with `ChildIndex=2`, it also tends to re-emit the
			//		scope with `ChildIndex=3` due to the condition.
			self.emitDefers(nds, true)
		}

		if !stmt {
			self.oc.doneIndent()
			self.oc.indent()
			self.oc.write("}")
		}
	}

	// Generates C++ code of a scope.
	// If the scope s is a deferred scope, memorizes it.
	fn scope(mut &self, mut s: &sema::Scope) {
		self.scope2(s, false)
	}

	// Generates C++ code of a scope.
	// If the scope s is a deferred scope, memorizes it.
	// If stmt is true, emits statements without placing braces.
	fn scope2(mut &self, mut s: &sema::Scope, stmt: bool) {
		// Scope is deferred.
		// Memorize it for deferred handling.
		if s.Deferred {
			self.deferredScopes = append(self.deferredScopes, s)
			ret
		}

		self.__scope(s, stmt)
	}

	fn commonFuncScope(mut &self, mut f: &sema::FuncIns, raw: bool) {
		if !f.Decl.IsVoid() {
			mut tup := f.Result.Tuple()
			if tup != nil {
				self.oc.indent()
				self.oc.tc.rc.tuple(&self.oc.Buf, tup)
				self.oc.write(" " + resultName + ";\n")
				for (i, mut t) in tup.Types {
					if shouldInitialized(t) {
						self.oc.indent()
						self.oc.write(resultName + "." + resultArgName)
						self.oc.write(conv::Itoa(i))
						self.oc.write(" = ")
						self.oc.ec.initExpr(t)
						self.oc.write(";\n")
					}
				}
			} else if len(f.Decl.Result.Names) == 1 {
				// Non-tuple single return type with identifier.
				// Use [resultName] as identifier.
				self.oc.indent()
				self.oc.tc.kind(&self.oc.Buf, f.Result)
				self.oc.write(" " + resultName)
				if shouldInitialized(f.Result) {
					self.oc.write(" = ")
					self.oc.ec.initExpr(f.Result)
				}
				self.oc.write(";\n")
			}
		}

		mut oldDeferredScopes := self.deferredScopes
		self.deferredScopes = nil
		defer { self.deferredScopes = oldDeferredScopes }

		nds := len(self.deferredScopes)

		self.scopeStmts(f.Scope)

		// Before executing final steps, checks whether the scope has final statement
		// already such as return statement or error call.
		if len(f.Scope.Stmts) > 0 {
			stmt := f.Scope.Stmts[len(f.Scope.Stmts)-1]
			match type stmt {
			| &sema::Ret:
				ret
			| &sema::Value:
				v := stmt.(&sema::Value)
				match type v.Model {
				| &sema::BuiltinErrorCallExpr
				| &sema::BuiltinPanicCallExpr:
					ret
				|:
					// no-op
				}
			|:
				// no-op
			}
		}

		// If we have new deferred scopes, emit them.
		// Because they are placed in this scope.
		self.emitDefers(nds, true)

		if !raw && f.Decl.IsVoid() {
			if f.Decl.Exceptional {
				// Just for void exceptionals.
				// Other cases checked by semantic analsis and disallowed
				// if they are not returns.
				self.oc.indent()
				self.oc.write(returnKw(f))
				self.oc.write(" __jule_VoidExceptional{};\n")
			} else {
				self.oc.indent()
				self.oc.write(returnKw(f))
				self.oc.write(";\n")
			}
		}
	}

	fn anonFuncScope(mut &self, mut m: &sema::AnonFuncExpr, name: str) {
		if m.Func.Scope == nil {
			ret
		}
		closure := obj::IsClosure(m)
		if closure {
			self.oc.ec.varPrefixes = append(self.oc.ec.varPrefixes,
				fn|mut v| captureVarHandling(self.oc, m, v))
		}
		self.oc.write("{\n")
		self.oc.addIndent()

		if closure {
			// Get ctx.
			self.oc.indent()
			self.oc.write(name)
			self.oc.write(anonFuncCtxSuffix + " *" + closureCtxIdent +
				" = (" + name + anonFuncCtxSuffix + "*)(" + ctxParamIdent + ");\n")
		}

		// Anonymous function may have different runtime model.
		oldAsync := self.oc.mode & _OBJ_ASYNC
		if m.Func.Decl.Async {
			self.oc.mode |= _OBJ_ASYNC
		} else {
			self.oc.mode &= ^_OBJ_ASYNC
		}

		self.commonFuncScope(m.Func, false)

		// Restore old runtime model.
		self.oc.mode |= oldAsync

		self.oc.doneIndent()
		self.oc.indent()
		self.oc.write("}")
		if closure {
			self.oc.ec.varPrefixes = self.oc.ec.varPrefixes[:len(self.oc.ec.varPrefixes)-1]
		}
	}

	// Generates C++ code of function's scope.
	fn funcScope(mut &self, mut f: &sema::FuncIns, raw: bool) {
		if f.Scope == nil {
			ret
		}

		// Save the mode and restore before return.
		mut mode := self.oc.mode
		defer { self.oc.mode = mode }

		// Update modes according to function.
		disable := obj::FindDirective(f.Decl.Directives, directive::Disable)
		if disable == nil {
			self.oc.mode &= ^_OBJ_DISABLE
		} else {
			self.oc.mode = obj::HasDirectiveArg(disable, "boundary", self.oc.mode, _OBJC_DISABLE_BOUNDARY)
			self.oc.mode = obj::HasDirectiveArg(disable, "nilptr", self.oc.mode, _OBJC_DISABLE_NILPTR)
		}
		if f.Decl.Async {
			self.oc.mode |= _OBJ_ASYNC
		} else {
			self.oc.mode &= ^_OBJ_ASYNC
		}

		self.oc.write("{\n")
		self.oc.addIndent()
		self.commonFuncScope(f, raw)
		self.oc.doneIndent()
		self.oc.indent()
		self.oc.write("}")

		// Clear keys for efficiency.
		delete(self.addrmap)
	}
}

fn isCopyOptimizable(v: &sema::Value, iter: bool): bool {
	// Return false if value is not lvalue or iter && mutable.
	// If the value is not lvalue, we have to copy it.
	// If the value is mutable and optimized for iteration, we cannot optimize it.
	// Because the value may be mutated in the iteration.
	// Compiler will not analysis such cases yet, so we cannot know.
	if !v.Lvalue || (iter && v.Mutable) {
		ret false
	}
	_, slicing := v.Model.(&sema::SlicingExpr)
	ret !slicing
}

fn isIterCopyOptimizable(val: &sema::Value, v: &sema::Var): bool {
	if !val.Lvalue && !val.Type.Mutable() {
		ret true
	}
	ret !v.Mutable && !val.Mutable
}

fn captureVarHandling(mut oc: &ObjectCoder, mut m: &sema::AnonFuncExpr, mut v: &sema::Var): bool {
	for _, cv in m.Captured {
		if cv == v {
			oc.write(closureCtxIdent + "->")
			identCoder.anonFuncVar(&oc.Buf, v)
			ret true
		}
	}
	ret false
}

fn returnKw(f: &sema::FuncIns): str {
	if f.Decl == nil || !f.Decl.Async {
		ret "return"
	}
	ret "__jule_AsyncRet"
}