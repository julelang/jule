// Copyright 2024-2025 The Jule Programming Language.
// Use of this source code is governed by a BSD 3-Clause
// license that can be found in the LICENSE file.

use "env"
use "obj"
use "obj/meta"
use "std/comptime"
use "std/jule/constant"
use "std/jule/sema"
use "std/jule/token"
use "std/jule/types"
use "std/math/bits"

// Expression optimizer that applies target-independent optimizations.
struct exprOptimizer {
	mut model:     &sema::Expr
	mut data:      &data // Should be non-nil guaranteed.
	mut inspector: &obj::ExprInspector
	mut scopeOpt:  &scopeOptimizer
}

impl exprOptimizer {
	static fn optimize(mut &model: sema::Expr) {
		exprOptimizer.optimizeValue(model, emptyData, nil)
	}

	static fn new(mut &model: sema::Expr, mut &d: &data, mut s: &scopeOptimizer): &exprOptimizer {
		ret &exprOptimizer{
			model: unsafe { (&sema::Expr)(&model) },
			data: d,
			inspector: obj::ExprInspector.New(),
			scopeOpt: s,
		}
	}

	static fn optimizeValue(mut &model: sema::Expr, mut &d: &data, mut s: &scopeOptimizer) {
		// Do optimizatitons if any enabled.
		if exprEnabled {
			mut exop := exprOptimizer.new(model, d, s)
			exop.do()
		}
	}

	// Like the optimizeData method, but any conditional expression
	// (such as x != nil) will be considered as optimization informative data.
	// Designed for conditional structures like if or match statements.
	static fn optimizeConditionalValue(mut &model: sema::Expr, mut &d: &data, mut s: &scopeOptimizer) {
		// Do optimizatitons if any enabled.
		if !exprEnabled {
			ret
		}
		mut exop := exprOptimizer.new(model, d, s)
		match type model {
		| &sema::BinaryExpr:
			// Binary expression model.
			// It should be handled in separate optimization routine.
			break
		|:
			// Normal expressions. Not binary, such as "test(*x)".
			// This expression is will be executed eventually.
			// Therefore, use ordinary optimization routine.
			exop.do()
			ret
		}

		// check is a flag to determine binary expression can check for conditional analysis.
		mut check := true
		mut _check := unsafe { (&bool)(&check) } // reference for the check variable used from closure

		exop.inspector.Inspect(*exop.model, fn(mut &m: sema::Expr) {
			if *_check {
				match type m {
				| &sema::BinaryExpr:
					mut binary := (&sema::BinaryExpr)(m)

					// Do not continue to checking. Binary expression is using || operator.
					// So we can't know whether operands are guaranteed to be executed.
					// For example:
					//
					//	if x != nil || y != nil { ... }
					//
					//	In the example code above, we can't know which operand is not nil.
					//
					// It also requires all binary expressions should be &&.
					// Because the first node is the root binary expression.
					// And by the CAST production, the || operator cames first than && operator.
					// So it breaks if binary expression is not uses only the && operator.
					*_check = binary.Op.Id != token::Id.DblVline
					if !*_check {
						break
					}

					exop.checkBinaryForBoundary(binary)
					exop.checkBinaryForNil(binary)
				}
			}
			exop.inspectStep(m)
		})
	}

	fn selfCmpCond(self, mut &m: &sema::BinaryExpr): bool {
		if m.Left.Type.Prim() != nil && types::IsFloat(m.Left.Type.Prim().Kind) {
			// Do not apply this optimization for flota data types.
			// It prevents tricks such as NaN conditions (x != x).
			ret false
		}
		if !obj::EqualModels(m.Left.Model, m.Right.Model) {
			ret false
		}
		match m.Op.Id {
		| token::Id.Eqs
		| token::Id.LtEq
		| token::Id.GtEq:
			// Operators used with itself: ==, <=, >=.
			// Evaluation will be always true.
			*self.model = constant::Const.NewBool(true)
			ret true
		| token::Id.NotEq
		| token::Id.Lt
		| token::Id.Gt:
			// Operators used with itself: !=, <, >.
			// Evaluation will be always false.
			*self.model = constant::Const.NewBool(false)
			ret true
		|:
			ret false
		}
	}

	fn boolCond(self, mut &m: &sema::BinaryExpr): bool {
		lp := m.Left.Type.Prim()
		if lp == nil || !lp.IsBool() {
			ret false
		}
		match type m.Left.Model {
		| &constant::Const:
			// Equality comparison, swap operation is safe and will not change
			// the behavior of the program.
			m.Left, m.Right = m.Right, m.Left
		|:
			match type m.Right.Model {
			| &constant::Const:
				break
			|:
				ret false
			}
		}
		mut c := (&constant::Const)(m.Right.Model)
		match m.Op.Id {
		| token::Id.DblAmper:
			if c.ReadBool() {
				// Use left operand as model directly.
				// Logical and with constant true expression is always will be true.
				// The non-constant left operand should be true,
				// this is the only important thing. So eliminate constant true.
				*self.model = m.Left.Model
			} else {
				// Logical and with constant false expression.
				// Binary expression is always will be false.
				c.SetBool(false)
				*self.model = c
			}
			ret true
		| token::Id.DblVline:
			if c.ReadBool() {
				// Logical or with constant true expression.
				// Binary expression is always will be true.
				c.SetBool(true)
				*self.model = c
			} else {
				// Use left operand as model directly.
				// Logical or with constant false expression is always will be false.
				// The non-constant left operand should be true,
				// this is the only important thing. So eliminate constant false.
				*self.model = m.Left.Model
			}
			ret true
		|:
		}
		ret false
	}

	fn arrayCond(self, mut m: &sema::BinaryExpr): bool {
		mut arr := m.Left.Type.Array()
		if arr == nil || arr.N != 0 {
			ret false
		}
		// type of the right operand should be the same array type with the left operand
		// there is no element to compare, so simplify expression to "true" expression
		// because arrays have same types and size with no element, this always results as "true"
		*self.model = constant::Const.NewBool(true)
		ret true
	}

	// Optimizes string conversions if possible.
	// It may apply optimizations with unsafe behaviors.
	// So make sure this optimizations are always safe for the scope.
	fn strConv(self, mut &m: &sema::OperandExpr) {
		p := m.Type.Prim()
		if p == nil || !p.IsStr() {
			ret
		}
		match type m.Model {
		| &sema::CastingExpr:
			// str(?)
			mut c := (&sema::CastingExpr)(m.Model)
			mut s := c.Expr.Type.Slice()
			if s == nil {
				break
			}
			sp := s.Elem.Prim()
			if sp == nil {
				break
			}
			if sp.IsU8() {
				// str([]byte)
				mut model := any(&StrFromBytes{Expr: c.Expr.Model})
				m.Model = unsafe { *(*sema::Expr)(&model) }
			}
		}
	}

	fn strCond(self, mut &m: &sema::BinaryExpr): bool {
		lp := m.Left.Type.Prim()
		if lp == nil || !lp.IsStr() {
			ret false
		}
		if m.Op.Id != token::Id.Eqs && m.Op.Id != token::Id.NotEq {
			ret false
		}
		match type m.Left.Model {
		| &constant::Const:
			// Equality comparison, swap operation is safe and will not change
			// the behavior of the program.
			m.Left, m.Right = m.Right, m.Left
		|:
			match type m.Right.Model {
			| &constant::Const:
				break
			|:
				ret false
			}
		}
		mut c := (&constant::Const)(m.Right.Model)
		match m.Op.Id {
		| token::Id.Eqs:
			if c.ReadStr() == "" {
				mut model := any(&EmptyCompareExpr{
					Expr: m.Left.Model,
					Neg: false,
				})
				*self.model = unsafe { *(*sema::Expr)(&model) }
				break
			}
			mut model := any(&StrCompExpr{
				Left: m.Left.Model,
				Right: c,
				NotEq: false,
			})
			*self.model = unsafe { *(*sema::Expr)(&model) }
		| token::Id.NotEq:
			if c.ReadStr() == "" {
				mut model := any(&EmptyCompareExpr{
					Expr: m.Left.Model,
					Neg: true,
				})
				*self.model = unsafe { *(*sema::Expr)(&model) }
				break
			}
			mut model := any(&StrCompExpr{
				Left: m.Left.Model,
				Right: c,
				NotEq: true,
			})
			*self.model = unsafe { *(*sema::Expr)(&model) }
		}
		ret true
	}

	// Tries to optimize string concatenations and reports whether applied.
	fn strConcat(self, mut &m: &sema::BinaryExpr): bool {
		lp := m.Left.Type.Prim()
		if lp == nil || !lp.IsStr() {
			ret false
		}
		if m.Op.Id != token::Id.Plus {
			ret false
		}

		// Check the left operand of the binary expression to determine we need to optimize it specifically.
		// Use the left perand because of CAST structure.
		// See the variable step and function body documentation about binary expressions.
		match type m.Left.Model {
		| &sema::BinaryExpr:
			// the left operand expression is binary expression
			// the expression is like: "x + y + ..."
			// we can optimize it
			break
		|:
			// expression is like: "x + y"
			// there is no need to optimize it
			ret false
		}

		mut model := new(StrConcatExpr)
		let mut step: fn(mut m: sema::Expr)
		// Point to the step variable in the closure. Otherwise it will be copied,
		// so the step function remains as nil, which is causes nil dereferencing.
		&_step := step
		step = fn(mut m: sema::Expr) {
			match type m {
			| &sema::BinaryExpr:
				// First, handle the left operand.
				// Parts should be in same addition order of the source code.
				// By operator precedence and CAST production,
				// the first node of the CAST is always the last binary expression.
				// For example:
				//	|
				//	| _ = "foo" + x + "bar" + "baz"
				//	|                       ^
				//	In the expression above, the first binary expression node will be pointed one.
				//	So handle `"foo" + x + "bar"` expression first, then the right operand `+ "baz"`.
				//	So, recursively handle the left binary expression operands,
				//	and push the expression models by left-to-right order.
				mut binary := (&sema::BinaryExpr)(m)
				unsafe {
					// Apply common optimizations for each binary expression.
					self.binaryStrCommon(binary)

					_step(binary.Left.Model)
					_step(binary.Right.Model)
				}
			|:
				model.Parts = append(model.Parts, m)
			}
		}
		// Start handling from the last binary expression m.
		// See documentation of the step function about binary expressions.
		step(m)

		mut anyModel := any(model)
		*self.model = unsafe { *(*sema::Expr)(&anyModel) }
		ret true
	}

	fn tryNeutralElement1(self, mut &m: &sema::BinaryExpr, mut c: &constant::Const, mut &nc: &sema::OperandExpr): bool {
		if c.IsStr() { // Constant is string, check for string optimizations.
			if !Str {
				ret false
			}
			if c.ReadStr() == "" && m.Op.Id == token::Id.Plus {
				// Concatenation with empty string, use the non-constant operand's model.
				*self.model = nc.Model
				ret true
			}
			ret false
		}

		// Following algorithms are designed for zero-constant math operations.
		// So make required conditions are guaranteed.
		if !Math || c.AsF64() != 0 {
			ret false
		}
		match m.Op.Id {
		| token::Id.Shl
		| token::Id.Shr:
			// If the constant expression is shifter, use the right operand's model.
			if nc == m.Left {
				*self.model = nc.Model
				ret true
			}
			// If the shifter expression is non-constant, shifted value is constant-zero.
			// Use zero-constant directly.
			*self.model = c
			ret true
		| token::Id.Star:
			if types::IsFloat(nc.Type.Prim().Kind) {
				// If type is float, do not apply this optimization.
				// Because multiplication with zero is not equals to zero always.
				// For example, 0*NaN != 0.
				break
			}
			c.SetI64(0)
			*self.model = c
			ret true
		| token::Id.Plus
		| token::Id.Minus:
			*self.model = nc.Model
			ret true
		}
		ret false
	}

	// Tries optimize binary expression for neutral elements.
	// Specialized in math optimizations.
	fn tryNeutralElement(self, mut &m: &sema::BinaryExpr): bool {
		// For neutral element optimization, one of the operands should be constant.
		match type m.Left.Model {
		| &constant::Const:
			mut c := (&constant::Const)(m.Left.Model)
			ret self.tryNeutralElement1(m, c, m.Right)
		}
		match type m.Right.Model {
		| &constant::Const:
			mut c := (&constant::Const)(m.Right.Model)
			ret self.tryNeutralElement1(m, c, m.Left)
		}
		ret false
	}

	fn checkBinaryForBoundary(self, mut &m: &sema::BinaryExpr) {
		if self.data.boundary == nil {
			ret
		}
		match type m.Left.Model {
		| &sema::BuiltinLenCallExpr:
			mut blc := (&sema::BuiltinLenCallExpr)(m.Left.Model)
			if !isBoundaryValidType(blc.Expr.Type) {
				ret
			}
			if m.Op.Id != token::Id.Gt && m.Op.Id != token::Id.Eqs {
				ret
			}
			// len(x) > y, len(x) == y (constant)
			// Max guaranteed size of x is y.
			if m.Op.Id == token::Id.Eqs {
				match type m.Right.Model {
				| &constant::Const:
					mut c := new(constant::Const, *(&constant::Const)(m.Right.Model)) // Do not mutate binary operand.
					c.Sub(*constant::Const.NewI64(1))
					self.data.boundary.pushVar(getBoundaryVar(blc.Expr.Model), c)
				}
				ret
			}
			self.data.boundary.pushVar(getBoundaryVar(blc.Expr.Model), m.Right.Model)
			ret
		}
		match type m.Right.Model {
		| &sema::BuiltinLenCallExpr:
			mut blc := (&sema::BuiltinLenCallExpr)(m.Right.Model)
			if !isBoundaryValidType(blc.Expr.Type) {
				ret
			}
			if m.Op.Id != token::Id.Lt && m.Op.Id != token::Id.Eqs {
				ret
			}
			// y < len(x), y (constant) == len(x)
			// Max guaranteed size of x is y.
			if m.Op.Id == token::Id.Eqs {
				match type m.Left.Model {
				| &constant::Const:
					mut c := new(constant::Const, *(&constant::Const)(m.Left.Model)) // Do not mutate binary operand.
					c.Sub(*constant::Const.NewI64(1))
					self.data.boundary.pushVar(getBoundaryVar(blc.Expr.Model), c)
				}
				ret
			}
			self.data.boundary.pushVar(getBoundaryVar(blc.Expr.Model), m.Left.Model)
			ret
		}
	}

	fn checkBinaryForNil(self, mut &m: &sema::BinaryExpr) {
		if self.data.nils == nil {
			ret
		}
		mut var := getNilVar(m.Left.Model)
		if var != invalidNil {
			if !isNilValidType(m.Left.Type) {
				ret
			}
			match type m.Right.Model {
			| &constant::Const:
				// No need to check whether constant variable is nil.
				// It only can be nil.
				self.data.nils.pushVar(var, m.Op.Id == token::Id.NotEq)
			}
			ret
		}
		var = getNilVar(m.Right.Model)
		if var != invalidNil {
			if !isNilValidType(m.Right.Type) {
				ret
			}
			match type m.Left.Model {
			| &constant::Const:
				// No need to check whether constant variable is nil.
				// It only can be nil.
				self.data.nils.pushVar(var, m.Op.Id == token::Id.NotEq)
			}
			ret
		}
	}

	// Applies optimization for binary shiftings.
	// This method assumes the right operand is constant.
	fn shift(self, mut m: &sema::BinaryExpr) {
		// semantic anlayzer guarantees right operator is unsigned if constant
		z := types::BitSizeOf(m.Left.Type.Prim().Kind)
		s := (&constant::Const)(m.Right.Model).AsU64()
		if s >= u64(z) {
			// shifting greater than bitsize of the left operand
			// discard all bits, result always equals to zero
			*self.model = constant::Const.NewU64(0)
			ret
		}
		// Set model to unsafe binary.
		// Value is not overflows the bitsize of the type.
		// So we can remove runtime cost of shifter checking.
		mut model := any(&UnsafeBinaryExpr{Node: m})
		*self.model = unsafe { *(*sema::Expr)(&model) }
	}

	// Tries to optimize binary expression with --opt-math optimization flag.
	// Assumes the math optimizations are enabled.
	// Reports whether optimization applied.
	fn binaryMath(self, mut &m: &sema::BinaryExpr): (applied: bool) {
		// Break optimizations if types are not primitive.
		// No need for checking whether types are arithmetic,
		// because relevant operators are only available for arithmetic primitives.
		lp := m.Left.Type.Prim()
		if lp == nil {
			ret false
		}
		rp := m.Right.Type.Prim()
		if rp == nil {
			ret false
		}

		match m.Op.Id {
		| token::Id.Plus:
			// If type is integer and expressions is like "x+x", then we can simplify to "x<<1" which is faster.
			// Floating-point types is exceptional because we cannot predict the result because of NaN or similar values.
			// Also floating-point types are not supports bit shifting operators.
			if !types::IsInt(lp.Kind) || !obj::EqualModels(m.Left.Model, m.Right.Model) {
				break
			}
			m.Op = new(token::Token, *m.Op)
			m.Op.Id = token::Id.Shl
			m.Op.Kind = token::Kind.Shl
			m.Right.Model = constant::Const.NewU64(1)
			// Set model to unsafe expression model. Because it is safe.
			// We can remove runtime cost of shifter checking.
			mut model := any(&UnsafeBinaryExpr{Node: m})
			*self.model = unsafe { *(*sema::Expr)(&model) }
			ret true
		| token::Id.Minus:
			// If type is integer and expressions is like "x-x", then we can simplify to "0" which is cheaper.
			// Floating-point types is exceptional because we cannot predict the result because of NaN or similar values.
			if !types::IsInt(lp.Kind) || !obj::EqualModels(m.Left.Model, m.Right.Model) {
				break
			}
			mut c := constant::Const.NewU64(0)
			c.Kind = lp.Kind
			*self.model = c
			ret true
		| token::Id.Amper:
			// Optimize x&0 and 0&x computations to 0.
			mut c, mut ok := (&constant::Const)(m.Right.Model)
			if ok {
				s := c.AsF64()
				if s == 0 {
					c = constant::Const.NewI64(0)
					c.Kind = lp.Kind
					*self.model = c
					ret true
				}
			}
			c, ok = (&constant::Const)(m.Left.Model)
			if ok {
				s := c.AsF64()
				if s == 0 {
					c = constant::Const.NewI64(0)
					c.Kind = rp.Kind
					*self.model = c
					ret true
				}
			}
			ret false
		| token::Id.Vline | token::Id.Caret:
			// Optimize x^0 and 0^x computations to x.
			mut c, mut ok := (&constant::Const)(m.Right.Model)
			if ok {
				s := c.AsF64()
				if s == 0 {
					*self.model = m.Left.Model
					ret true
				}
			}
			c, ok = (&constant::Const)(m.Left.Model)
			if ok {
				s := c.AsF64()
				if s == 0 {
					*self.model = m.Right.Model
					ret true
				}
			}
			ret false
		}

		// Check whether the right operand is constant for safety.
		// The following algorithms assumes the right operand is constant.
		match type m.Right.Model {
		| &constant::Const:
			break
		|:
			ret false
		}

		match m.Op.Id {
		| token::Id.Star:
			if types::IsInt(lp.Kind) && types::IsUnsigInt(rp.Kind) {
				ok, x := checkForBitShiftOpt(m.Left, m.Right)
				if ok {
					m.Op = new(token::Token, *m.Op)
					m.Op.Id = token::Id.Shl
					m.Op.Kind = token::Kind.Shl
					mut c := (&constant::Const)(m.Right.Model)
					c.SetU64(x)
					self.shift(m) // We should try to optimize new optimized shifting expression.
					ret true
				}
			}
		| token::Id.Percent:
			if types::IsUnsigInt(lp.Kind) {
				mut c := (&constant::Const)(m.Right.Model)
				if c.AsF64() == 0b10 {
					m.Op = new(token::Token, *m.Op)
					m.Op.Id = token::Id.Amper
					m.Op.Kind = token::Kind.Amper
					c.SetI64(1)
					// No need to set model as UnsafeBinaryExpr,
					// bitwise and is not checked at runtime, so it is optimize enough.
					ret true
				}
			}
		| token::Id.Shl | token::Id.Shr:
			self.shift(m)
			ret true
		|:
			// Eliminate unsupported operators.
			ret false
		}
		// Update model as UnsafeBinaryExpr because it is safe, comptime checked.
		// There is no risk like zero-division.
		mut model := any(&UnsafeBinaryExpr{Node: m})
		*self.model = unsafe { *(*sema::Expr)(&model) }
		ret true
	}

	// Common string optimizations for binary expressions.
	// Always make sure this optimization will not block the following analysis.
	fn binaryStrCommon(self, mut &m: &sema::BinaryExpr) {
		self.strConv(m.Left)
		self.strConv(m.Right)
	}

	fn binary(self, mut m: &sema::BinaryExpr) {
		if Str {
			self.binaryStrCommon(m)
			match {
			| self.strCond(m)
			| self.strConcat(m):
				goto end
			}
		}
		if Array && self.arrayCond(m) {
			goto end
		}
		if Cond {
			match {
			| self.boolCond(m)
			| self.selfCmpCond(m):
				goto end
			}
		}
		if self.tryNeutralElement(m) {
			goto end
		}
		if Math && self.binaryMath(m) {
			goto end
		}

	end:
		if m.Op.Id == token::Id.DblVline {
			// Binary expression uses the || operator.
			// We should ignore optimization information updates.
			// Because we can't whether they are really informative.
			// For example:
			//
			//	x := (&int)(nil)
			//	y := (&int)(nil)
			//	if x != nil || *y == 20 {
			//		println(*y)
			//	}
			//
			//	In the example code above, we can't assume |y| is dereferenced, so checked.
			//	Optimization analysis will update the optimization data. So,
			//	if we don't use immutable checkpoint copy, the optimizer will
			//	optimize |*y| expression of the println call, which is dangerous.
			//	Therefore we have to handle data for operands.
			//	To achieve that, get immutable checkpoint, optimize operands,
			//	then load data to checkpoint copy.
			//
			// There is another issue. Internal data usage should be allowed.
			// For example:
			//
			//	if x != nil || foo(*y, *y)
			//
			//	In the example code above, if the function |foo| called,
			//	we know the |y| dereferenced twice. So, able to optimize the
			//	second dereferencing. It should be allowed. So, the checkpoint
			//	will help for that also. We can use data for the internal optimizations,
			//	then ignore the optimization updates and restore to the checkpoint.
			mut checkpoint := data{}
			checkpoint.loadCheckpoint(self.data.getCheckpoint())

			unsafe { self.inspector.InspectStep(m.Left.Model) }
			// Load from hard copy checkpoint of checkpoint data here.
			// Because soft checkpoint loading uses direct data.
			// So if data mutated, checkpoint will be mutated also.
			// We may lost the checkpoint data, therefore use hard-copy.
			self.data.loadCheckpoint(checkpoint.getCheckpoint())

			unsafe { self.inspector.InspectStep(m.Right.Model) }
			// There is no risk for checkpoint data mutation. Do soft load.
			self.data.loadCheckpoint(checkpoint.getMutCheckpoint())

			// Children are optimized. Now, we can skip children of binary expression.
			// Avoid duplicated analysis.
			self.inspector.SkipChild = true
		}
	}

	fn unary(self, mut m: &sema::UnaryExpr) {
		if !Ptr {
			ret
		}
		match m.Op.Id {
		| token::Id.Star:
			match type m.Expr.Model {
			| &sema::UnaryExpr:
				mut um := (&sema::UnaryExpr)(m.Expr.Model)
				if um.Op.Id == token::Id.Amper {
					// Remove pointer overhead.
					// Expression is: *(&x)
					// Simplify to: x
					*self.model = um.Expr.Model
				}
				ret
			}
			if Access && self.data.nils != nil && isNilValidType(m.Expr.Type) {
				var := getNilVar(m.Expr.Model)
				if self.data.nils.isSafe(var) {
					mut model := any(&UnsafeDerefExpr{Base: m})
					*self.model = unsafe { *(*sema::Expr)(&model) }
				} else {
					// Now this variable is safe until it mutated.
					self.data.nils.pushVar(var, true)
				}
			}
		| token::Id.Amper:
			match type m.Expr.Model {
			| &sema::Var:
				mut v := (&sema::Var)(m.Expr.Model)
				if v.Reference {
					mut model := any(&RefExpr{Var: v})
					*self.model = unsafe { *(*sema::Expr)(&model) }
				}
			}
		}
	}

	fn structureLit(self, mut m: &sema::StructLitExpr) {
		for (_, mut arg) in m.Args {
			if self.data.boundary != nil {
				if isBoundaryRiskyType(arg.Expr.Type) {
					possibleBoundaryRemove(self.data.boundary, arg)
				}
			}
			if self.data.nils != nil {
				possibleNilRemove(self.data.nils, arg.Expr.Model)
			}
			if self.data.dynamic != nil {
				possibleDynamicRemove(self.data.dynamic, arg.Expr.Model)
			}
		}
	}

	fn typeAssertion(self, mut m: &sema::TypeAssertionExpr) {
		valid := isDynamicValidType(m.Expr.Type)
		var := getDynamicVar(m.Expr.Model)
		if valid && self.data.dynamic != nil && self.data.dynamic.isFits(var, m.Type) {
			mut model := any(&UnsafeTypeAssertionExpr{Base: m})
			*self.model = unsafe { *(*sema::Expr)(&model) }
			self.inspector.SkipChild = true
			ret
		}
		if self.data.dynamic != nil && valid {
			self.data.dynamic.pushVar(var, m.Type)
		}
	}

	fn args(self, mut params: []&sema::ParamIns, mut &args: []sema::Expr) {
		for (i, mut arg) in args {
			if i >= len(params) {
				continue
			}
			mut p := params[i]
			if p.Decl.Mutable && p.Decl.Reference {
				if self.data.boundary != nil {
					if isBoundaryRiskyType(p.Type) {
						possibleBoundaryRemove(self.data.boundary, arg)
					}
				}
				if self.data.nils != nil {
					possibleNilRemove(self.data.nils, arg)
				}
				if self.data.dynamic != nil {
					possibleDynamicRemove(self.data.dynamic, arg)
				}
			}
		}
	}

	// Tries to optimize scope.
	// If the |child| true and |self.scopeOpt| is not nil, calls the optimizeChildHard().
	// Otherwise optimizes the scope with immutable copy of the data if exist.
	fn scope(self, mut &s: &sema::Scope, child: bool) {
		if child && self.scopeOpt != nil {
			self.scopeOpt.optimizeChildHard(s)
			ret
		}
		mut scopt := scopeOptimizer.new(s)
		if self.data != nil {
			// If data exist, use it as immutable copy.
			// Because this scope is not child.
			// So, assume the child is not affect the parent.
			scopt.data = new(data)
			scopt.data.loadCheckpoint(self.data.getCheckpoint())
		}
		scopt.optimize()
	}

	fn optimizeStrBuilderCall(self, mut &m: &sema::FuncCallExpr) {
		// Some strings::Builder methods are not real-exceptional implementations.
		// They just implements interfaces and not throws any exceptional.
		// Therefore we can remove exceptional handling algorithms for these method calls.
		const meta = comptime::ValueOf(*meta::Program.StrBuilder)
		const for _, f in meta.Type().Decl().Fields() {
			if meta.Field(f.Name()).Unwrap() == m.Func {
				mut model := any(&FuncCallIgnoreExceptionalExpr{Base: m})
				*self.model = unsafe { *(*sema::Expr)(&model) }
				// Return function, skip following if statements if exist.
				ret
			}
		}
	}

	fn copyCall(self, mut m: &sema::BuiltinCopyCallExpr) {
		if !ZCopy {
			ret
		}
		// We have to use mutable memory for the dest argument of copy due to lang spec.
		// But we can optimize the src argument too, it is safe.
		// Optimization of the dest argument belongs to the back-end.
		if IsZCopyArray(m.Src.Model) {
			mut ie := (&sema::SlicingExpr)(m.Src.Model)

			// Special case: already optimized.
			_, ok := (&ArrayAsSlice)(unsafe { *(*any)(&ie.Expr.Model) })
			if ok {
				ret
			}

			mut model := any(&ArrayAsSlice{
				Expr: ie.Expr.Model,
			})
			ie.Expr.Model = unsafe { *(*sema::Expr)(&model) }
		}
	}

	fn appendCall(self, mut m: &sema::BuiltinAppendCallExpr) {
		if !ZAppend {
			ret
		}
		if IsZAppendArray(m.Elements.Model) {
			mut ie := (&sema::SlicingExpr)(m.Elements.Model)

			// Special case: already optimized.
			_, ok := (&ArrayAsSlice)(unsafe { *(*any)(&ie.Expr.Model) })
			if ok {
				ret
			}

			mut model := any(&ArrayAsSlice{
				Expr: ie.Expr.Model,
			})
			ie.Expr.Model = unsafe { *(*sema::Expr)(&model) }
		}
	}

	fn lenCall(self, mut m: &sema::BuiltinLenCallExpr) {
		if !Len {
			// skip optimizations if relevant flag is not passed
			ret
		}
		match type m.Expr.Model {
		| &sema::CastingExpr:
			break
		|:
			ret
		}
		mut c := (&sema::CastingExpr)(m.Expr.Model)
		mut prim := c.Expr.Type.Prim()
		if prim == nil || !prim.IsStr() {
			ret
		}
		// len((?)(str))
		mut slc := c.Type.Slice()
		if slc == nil {
			ret
		}
		prim = slc.Elem.Prim()
		if prim == nil {
			ret
		}
		// len(([]?)(str))
		match {
		| prim.IsU8():
			// len(([]byte)(str))
			// simplify expression to len(str), avoid making byte slice allocation
			m.Expr = c.Expr
		| prim.IsI32():
			// len(([]rune)(str))
			// simplify expression to runtime::runeCount, avoid making rune slice allocation
			mut func := meta::Program.Runtime.RuneCount
			*self.model = &sema::FuncCallExpr{
				Func: func,
				Expr: func,
				Args: [c.Expr.Model],
			}
		}
	}

	fn funcCall(self, mut m: &sema::FuncCallExpr) {
		self.args(m.Func.Params, m.Args)
		if m.Except != nil {
			// Handle exceptional handler scope as child.
			// Because it is actually a child scope.
			const Child = true
			self.scope(m.Except, Child)
		}
		match {
		| StdStrings && meta::Program.StrBuilder != nil:
			self.optimizeStrBuilderCall(m)
		}
	}

	fn indexing(self, mut m: &sema::IndexingExpr) {
		if !Access {
			ret
		}

		array := m.Expr.Type.Array()
		if array != nil {
			// Constants checked by semantic analysis for arrays, safe.
			if m.Index.IsConst() {
				mut model := any(&UnsafeIndexingExpr{Node: m})
				*self.model = unsafe { *(*sema::Expr)(&model) }
				ret
			}
			// If array length is power of two, optimize masked expressions if possible.
			// Like expression array[i&(len(array)-1)] will always be within the bounds.
			if isPowerOfTwo(u64(array.N)) {
				mask := u64(array.N - 1)
				bin, mut ok := (&sema::BinaryExpr)(m.Index.Model)
				if ok && bin.Op.Kind == token::Kind.Amper {
					{
						c, (ok) := (&constant::Const)(bin.Left.Model)
						if ok && c.AsU64() == mask {
							mut model := any(&UnsafeIndexingExpr{Node: m})
							*self.model = unsafe { *(*sema::Expr)(&model) }
						}
					}
					{
						c, (ok) := (&constant::Const)(bin.Right.Model)
						if ok && c.AsU64() == mask {
							mut model := any(&UnsafeIndexingExpr{Node: m})
							*self.model = unsafe { *(*sema::Expr)(&model) }
						}
					}
				}
			}
		}

		if self.data.boundary != nil && isBoundaryValidType(m.Expr.Type) {
			var := getBoundaryVar(m.Expr.Model)
			if self.data.boundary.fitsMaxSize(var, m.Index.Model) {
				mut model := any(&UnsafeIndexingExpr{Node: m})
				*self.model = unsafe { *(*sema::Expr)(&model) }
				ret
			}
			self.data.boundary.pushVar(var, m.Index.Model)
		}
	}

	fn anonFunc(self, mut m: &sema::AnonFuncExpr) {
		// Do not handle anonymous function body as child scope.
		// Handle it with separate block. There is no direct affect to parent scope.
		// It is possible with references, but it is unsafe operation.
		// So optimizer is not have to thing such cases.
		const Child = false
		self.scope(m.Func.Scope, Child)
	}

	fn inspectStep(self, mut &m: sema::Expr) {
		self.model = unsafe { (&sema::Expr)(&m) }
		match type m {
		| &sema::BinaryExpr:
			self.binary((&sema::BinaryExpr)(m))
		| &sema::UnaryExpr:
			self.unary((&sema::UnaryExpr)(m))
		| &sema::StructLitExpr:
			self.structureLit((&sema::StructLitExpr)(m))
		| &sema::TypeAssertionExpr:
			self.typeAssertion((&sema::TypeAssertionExpr)(m))
		| &sema::FuncCallExpr:
			self.funcCall((&sema::FuncCallExpr)(m))
		| &sema::BuiltinCopyCallExpr:
			self.copyCall((&sema::BuiltinCopyCallExpr)(m))
		| &sema::BuiltinAppendCallExpr:
			self.appendCall((&sema::BuiltinAppendCallExpr)(m))
		| &sema::BuiltinLenCallExpr:
			self.lenCall((&sema::BuiltinLenCallExpr)(m))
		| &sema::IndexingExpr:
			self.indexing((&sema::IndexingExpr)(m))
		| &sema::AnonFuncExpr:
			self.anonFunc((&sema::AnonFuncExpr)(m))
		}
	}

	fn do(self) {
		self.inspector.Inspect(*self.model, fn(mut &m: sema::Expr) {
			unsafe { self.inspectStep(m) }
		})
	}
}

// Checks for bit-shifting optimizations.
//
// Reports true if conditions are:
// - l is integer
// - r is integer
// - r is constant
// - r is power of two
//
// As a result: returns whether bit-shifting is possible and what nth power of 2^r.
// Assumes the model r is constant.
fn checkForBitShiftOpt(mut &l: &sema::OperandExpr, mut &r: &sema::OperandExpr): (ok: bool, x: u64) {
	lp := l.Type.Prim()
	rp := r.Type.Prim()
	if !types::IsInt(lp.Str()) || !types::IsInt(rp.Str()) {
		ret false, 0
	}
	x = (&constant::Const)(r.Model).AsU64()
	if !isPowerOfTwo(x) {
		ret false, 0
	}
	ok = true
	x = u64(bits::TrailingZeros64(x))
	ret
}

fn isPowerOfTwo(x: u64): bool {
	ret x != 0 && x&(x-1) == 0
}

// Reports l and r the same lvalue expression.
fn areSameLvalueExpr(&l: sema::Expr, &r: sema::Expr): bool {
	match type l {
	| &sema::Var:
		// Compare values directly.
		// If the l and r have same pointers, means same variable.
		ret l == r
	| &sema::StructSubIdentExpr:
		match type r {
		| &sema::StructSubIdentExpr:
			break
		|:
			ret false
		}
		lsi := (&sema::StructSubIdentExpr)(l)
		rsi := (&sema::StructSubIdentExpr)(r)
		// Compare fields directly.
		// If the l and r have same pointers,
		// means same variable of same struct instance.
		if lsi.Field != rsi.Field {
			ret false
		}
		// Check head expressions used for field access.
		ret areSameLvalueExpr(lsi.Expr.Model, rsi.Expr.Model)
	| &sema::UnaryExpr:
		match type r {
		| &sema::UnaryExpr:
			ul := (&sema::UnaryExpr)(l)
			ur := (&sema::UnaryExpr)(r)
			// Unary operators should have the same operator.
			// The operator does not matter.
			if ul.Op.Id != ur.Op.Id || ul.Op.Kind != ur.Op.Kind {
				ret false
			}
			// Check expressions used for unary.
			ret areSameLvalueExpr(ul.Expr.Model, ur.Expr.Model)
		}
	}
	ret false
}